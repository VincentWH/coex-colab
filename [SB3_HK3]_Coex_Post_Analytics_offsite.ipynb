{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VincentWH/coex-colab/blob/colab_pr/%5BSB3_HK3%5D_Coex_Post_Analytics_offsite.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7oTzg4WVDl2"
      },
      "source": [
        "#Coex Post Analytics\n",
        "\n",
        "Coex Post Analytics helps to query the coex testing data and generates the plogs.\n",
        "\n",
        "Please follow the steps to start the analytics.\n",
        "1. Connect to public borg by clicking **Connect** button in the top right. Select **Start** tab, **borg runtime**, and select **DeepMind CPU**, Once the runtime connected, the icon will show: ![Screen Shot 2020-09-28 at 2.12.30 PM.png](data:image/png;base64,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)\n",
        "\n",
        "\n",
        "2. By each test case, e.g. Sensor, Camera Dark Frame, please press the play of each cell in sequence:\n",
        "   -  **Query data**\n",
        "   -  **Serials filter**\n",
        "   -  **Plot**\n",
        "   -  **Data table**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsmMZFSRVCiH"
      },
      "source": [
        "#@title Project Configs<br></br> {run: \"auto\"}\n",
        "\n",
        "Project='hk3' #@param ['sb3', 'hk3'] {type:'string',isTemplate: true}\n",
        "Build='PROTO' #@param ['PROTO', 'PROTO1.0', \"PROTO1.1\", \"EVT\", \"DVT\", \"PVT\"] {type:'string',isTemplate: true}\n",
        "Type='offline' #@param ['offline', 'offsite']\n",
        "Start_Date='2022-10-15' #@param {type:'date',isTemplate: true}\n",
        "Last_Date='2022-11-30' #@param {type:'date',isTemplate: true}\n",
        "Latest_Data = True #@param {type: 'boolean'}\n",
        "\n",
        "\n",
        "\"\"\"Query the Coex testing data and generates the plogs.\"\"\"\n",
        "from collections import defaultdict, namedtuple\n",
        "from dataclasses import dataclass\n",
        "from datetime import datetime\n",
        "from enum import Enum\n",
        "from io import StringIO\n",
        "from pathlib import Path\n",
        "from time import gmtime, strftime\n",
        "import argparse\n",
        "import logging\n",
        "import multiprocessing as mp\n",
        "import pickle\n",
        "import re\n",
        "#import warnings\n",
        "\n",
        "from bokeh.layouts import layout, column, Spacer\n",
        "from bokeh.models import ColumnDataSource, Label, Div, HoverTool\n",
        "from bokeh.palettes import Spectral10\n",
        "from bokeh.plotting import figure, show, output_file, save\n",
        "from google.colab import auth, data_table, files, output\n",
        "from IPython.core.display import display\n",
        "from IPython.display import HTML, Javascript\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from plotly import subplots\n",
        "from plotly.graph_objs import Heatmap, Layout, Figure\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from pytz import timezone\n",
        "import holoviews as hv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pexpect\n",
        "\n",
        "# Try to filter out pandas error and warning\n",
        "pd.options.mode.chained_assignment = None # default='warn'\n",
        "warnings.filterwarnings('ignore', 'This pattern has match groups')\n",
        "# Try to filter out no module named 'oauth2client.locked_file' error\n",
        "logging.getLogger('googleapiclient.discovery_cache').setLevel(logging.ERROR)\n",
        "\n",
        "PROJECT_CSV = namedtuple('project_csv', 'sensor logs factory')\n",
        "CSV_FILES = {\n",
        "    'offline':\n",
        "    {\n",
        "        'hk3': PROJECT_CSV('10qmCwoywSJhPlx6_rKuiSDKhY09oDBIY',\n",
        "                           '19jYN9YKb4iEg1eW0PWuz3W4eTjevNae8',\n",
        "                           '1mi5smeX5ixPcWAQ0CiYz4u8d2qyV-zmG'),\n",
        "        'sb3': PROJECT_CSV('1iOhWh6vAPeihFOCTrac5A6aLKWj2_Pas',\n",
        "                           '1MlbvmDKFB2SavB2Tm2fNgM1WKtFk9OG0',\n",
        "                           '1X7gU2UrIj3j07q9uYWnJnJqDaG7Yj9yz'),\n",
        "    },\n",
        "    'offsite':\n",
        "    {\n",
        "        'hk3': PROJECT_CSV('1tkIwdsX5R2fHSu0d18HuCvd_qKvYtrPd',\n",
        "                            '1vnQjGAPuJYJ8vK8LC7lJtMaYWXgxo8hZ',\n",
        "                            '1qOmv2SfAM3VSgNVyi2saJfDkvQWjFJhB'),\n",
        "        'sb3': PROJECT_CSV('130xrKM9SsQB_9z2B5saDX89iDXPeDwL2',\n",
        "                            '1-tL2NXFXgQe_i7iXGwCIrA3adfmVs2TF',\n",
        "                            '1W1eAfByRj1MEsggADGys2tVzQ-hhoap4'),\n",
        "    }\n",
        "    \n",
        "}\n",
        "\n",
        "class Table(Enum):\n",
        "    \"\"\"Contains the folder of google drive use for query.\"\"\"\n",
        "    SENSOR = 0\n",
        "    LOGS = 1\n",
        "    FACTORY = 2\n",
        "\n",
        "\n",
        "class StatusError(IndexError):\n",
        "    \"\"\"Raised when the station data is empty.\"\"\"\n",
        "\n",
        "\n",
        "class Base():\n",
        "    \"\"\"Class definition for base function.\"\"\"\n",
        "    def GetSerialsList(src_df):\n",
        "        \"\"\"\n",
        "        The complete serial list is in logs dataframe, since it collects all\n",
        "        the log attachments, but test dataframe could miss some test data.\n",
        "        \"\"\"\n",
        "        return src_df[src_df['serial'].notna()]['serial'].unique().tolist()\n",
        "\n",
        "    def GetTestCasesList(src_df):\n",
        "        return src_df[src_df['test_case'].notna()].test_case.unique().tolist()\n",
        "\n",
        "    def GetTestItemsList(src_df):\n",
        "        \"\"\"\n",
        "        The complete test items list is in test dataframe,\n",
        "        since it contains all test items.\n",
        "        \"\"\"\n",
        "        return src_df[src_df['test_item'].notna()].test_item.unique().tolist()\n",
        "\n",
        "    def GetSensorsList(src_df):\n",
        "        if 'sensor_name' in src_df.columns:\n",
        "            return src_df[src_df['sensor_name'].notna()].sensor_name.unique().tolist()\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def FindMissingRaws(src_df, serials_list, test_cases_list,\n",
        "                        test_items_list=None, sensors_list=None):\n",
        "        if sensors_list:\n",
        "            indices_list = ['serial', 'test_case', 'sensor_name']\n",
        "            product_list = [serials_list, test_cases_list, sensors_list]\n",
        "        elif test_items_list:\n",
        "            indices_list = ['serial', 'test_case', 'test_item']\n",
        "            product_list = [serials_list, test_cases_list, test_items_list]\n",
        "        else:\n",
        "            indices_list = ['serial', 'test_case']\n",
        "            product_list = [serials_list, test_cases_list]\n",
        "\n",
        "        src_df.set_index(indices_list, inplace=True)\n",
        "        complete_index = pd.MultiIndex.from_product(product_list,\n",
        "                                                    names=indices_list)\n",
        "        missing_index = complete_index.difference(src_df.index)\n",
        "        missing_df = pd.DataFrame(index=missing_index, columns=src_df.columns)\n",
        "        missing_df.reset_index(inplace=True)\n",
        "        src_df.reset_index(inplace=True)\n",
        "\n",
        "        if sensors_list:\n",
        "            for test_case in test_cases_list:\n",
        "                if not test_items_list:\n",
        "                    test_items_list = Base.GetTestItemsList(src_df)\n",
        "                test_item_data = next(x for x in test_items_list if test_case in x)\n",
        "                missing_df.loc[missing_df.test_case == test_case,\n",
        "                               'test_item'] = test_item_data\n",
        "        return missing_df\n",
        "\n",
        "    def GetDataframeBySerial(src_df, serials):\n",
        "        out_df = src_df.set_index(['serial'])\n",
        "        out_df = out_df.loc[serials]\n",
        "        return out_df.reset_index()\n",
        "\n",
        "    def GetDataframeStatus(src_df):\n",
        "        if src_df.empty:\n",
        "            raise StatusError(f'There are no data in this station yet between {Start_Date} and {Last_Date}.')\n",
        "\n",
        "    def FillMissingLogs(missing_df, logs_df):\n",
        "        missing_serials_list = Base.GetSerialsList(missing_df)\n",
        "        logs_source_df = Base.GetDataframeBySerial(logs_df,\n",
        "                                                   missing_serials_list)\n",
        "        missing_df.set_index(['serial', 'test_case'], inplace=True)\n",
        "        logs_source_df.set_index(['serial', 'test_case'], inplace=True)\n",
        "        missing_df.drop(logs_source_df.columns, axis=1, inplace=True)\n",
        "        missing_df = missing_df.join(logs_source_df)\n",
        "        logs_source_df.reset_index(inplace=True)\n",
        "        missing_df.reset_index(inplace=True)\n",
        "        return missing_df\n",
        "\n",
        "    def FillTestItemOfMissingDataframe(missing_df, logs_df, test_cases_list, test_items_list, test_item_key=None, key_mask=''):\n",
        "        for test_case in test_cases_list:\n",
        "            if not test_item_key:\n",
        "                test_item_key=test_case.replace(key_mask, '')\n",
        "            sub_test_items = [x for x in test_items_list if test_item_key in x ]\n",
        "            test_item_len = len(missing_df[missing_df['test_case'] == test_case])\n",
        "            sub_test_items_count = int(test_item_len/len(sub_test_items))\n",
        "            test_item_data = np.tile(sub_test_items, sub_test_items_count)\n",
        "            missing_df.loc[missing_df.test_case == test_case,\n",
        "                           'test_item'] = test_item_data\n",
        "        return missing_df\n",
        "\n",
        "    def FillDeviceConfigOfMissingDataframe(missing_df, logs_df):\n",
        "        serials = missing_df[missing_df['device_config'].isna()].serial.unique().tolist()\n",
        "        logs_df.set_index('serial', inplace=True)\n",
        "        missing_df.set_index('serial', inplace=True)\n",
        "        config_series=logs_df.loc[serials]['device_config'].dropna()\n",
        "        config_df = config_series.reset_index()\n",
        "        config_df.drop_duplicates(inplace=True)\n",
        "        config_dict = config_df.to_dict('records')\n",
        "\n",
        "        for item in config_dict:\n",
        "            missing_df.loc[item['serial'], 'device_config'] = item['device_config']\n",
        "\n",
        "        logs_df.reset_index(inplace=True)\n",
        "        missing_df.reset_index(inplace=True)\n",
        "        return missing_df\n",
        "\n",
        "    def FillSensorNameOfMissingDataframe(missing_df, test_df, sensors_list):\n",
        "        sensor_len = len(sensors_list)\n",
        "        output_df = pd.DataFrame(columns=missing_df.columns)\n",
        "        test_cases_list = Base.GetTestCasesList(test_df)\n",
        "        missing_df.set_index('test_case', inplace=True)\n",
        "        for test_case in test_cases_list:\n",
        "            temp_df = missing_df.loc[test_case]\n",
        "            temp_df.reset_index(inplace=True)\n",
        "            temp_df_len = len(temp_df)\n",
        "            temp_df = pd.concat([temp_df]*sensor_len)\n",
        "            sensor_data = np.repeat(sensors_list, temp_df_len)\n",
        "            temp_df['sensor_name'] = sensor_data\n",
        "            output_df = output_df.append(temp_df, sort=False, ignore_index=True)\n",
        "\n",
        "        missing_df.reset_index(inplace=True)\n",
        "        return output_df\n",
        "\n",
        "    def FillColumnsOfMissingDataframe(missing_df, logs_df, test_cases_list,\n",
        "                                      test_items_list, test_item_key=None, key_mask=''):\n",
        "        missing_df = Base.FillDeviceConfigOfMissingDataframe(missing_df, logs_df)\n",
        "\n",
        "        # Fill station and build_phase\n",
        "        station=logs_df[logs_df['station'].notna()].iloc[0]['station']\n",
        "        build_phase=logs_df[logs_df['build_phase'].notna()].iloc[0]['build_phase']\n",
        "        values={'station':station, 'build_phase':build_phase}\n",
        "        missing_df.fillna(value=values, inplace=True)\n",
        "        return missing_df\n",
        "\n",
        "    def CreateMissingDataframe(test_df, logs_df, test_item_key=None, key_mask=''):\n",
        "        merged_df = logs_df.merge(test_df, how='left')\n",
        "        serials_list = Base.GetSerialsList(logs_df)\n",
        "        test_cases_list = Base.GetTestCasesList(test_df)\n",
        "        sensors_list = Base.GetSensorsList(test_df)\n",
        "        test_items_list = Base.GetTestItemsList(test_df)\n",
        "\n",
        "        missing_df = Base.FindMissingRaws(merged_df, serials_list,\n",
        "                                          test_cases_list,\n",
        "                                          test_items_list=test_items_list,\n",
        "                                          sensors_list=sensors_list)\n",
        "        missing_df = Base.FillMissingLogs(missing_df, logs_df)\n",
        "        missing_df = Base.FillColumnsOfMissingDataframe(missing_df, logs_df,\n",
        "                                                        test_cases_list,\n",
        "                                                        test_items_list,\n",
        "                                                        test_item_key=test_item_key,\n",
        "                                                        key_mask=key_mask)\n",
        "        return missing_df\n",
        "\n",
        "    def MergeDataframes(df, missing_df, check_dup_cols):\n",
        "        if Latest_Data:\n",
        "            df.sort_values(by=['log_date', 'log_time'], ascending=True, inplace=True)\n",
        "            df.dropna(subset=['test_item'], inplace=True)\n",
        "            df.drop_duplicates(subset=check_dup_cols, keep='last', inplace=True)\n",
        "            df = df.append(missing_df, sort=False)\n",
        "            df.drop_duplicates(subset=check_dup_cols, keep='first', inplace=True)\n",
        "            return df\n",
        "        else:\n",
        "            return df\n",
        "\n",
        "    def MergeDataLogs(log_df, test_df):\n",
        "        df = log_df.merge(\n",
        "            test_df,\n",
        "            how='left',\n",
        "            on=['serial', 'test_case', 'build_phase', 'log_date', 'log_time'])\n",
        "        return df\n",
        "\n",
        "    def ProcessCameraData(test_df, logs_df, camera_name):\n",
        "        src_df=logs_df.merge(test_df, how='left', on=['serial',\n",
        "                                                      'test_case',\n",
        "                                                      'build_phase'])\n",
        "        camera_df=src_df[src_df.test_case.str.contains(camera_name)]\n",
        "        # To fill missing dataframe, we need sub_test_df for specific camera data,\n",
        "        # or we get useless data.\n",
        "        sub_test_df = test_df[test_df.test_case.str.contains(camera_name)].dropna()\n",
        "\n",
        "        missing_df = Base.CreateMissingDataframe(sub_test_df,\n",
        "                                                 logs_df,\n",
        "                                                 key_mask=camera_name)\n",
        "        camera_df = Base.MergeDataframes(camera_df, missing_df, ['serial',\n",
        "                                                                 'test_case',\n",
        "                                                                 'test_item'])\n",
        "        camera_df = camera_df.dropna(subset = [\"test_item\"])\n",
        "        camera_df.sort_values(by=['test_item', 'serial'],\n",
        "                              ascending=False, inplace=True)\n",
        "        return camera_df\n",
        "\n",
        "    def GetDeviceConfigList(src_df):\n",
        "        \"\"\"The device configs list in dataframe.\"\"\"\n",
        "        return src_df[src_df['device_config'].notna()] \\\n",
        "            ['device_config'].unique().tolist()\n",
        "\n",
        "    def GetData(logs_df, latest_only):\n",
        "        cache = {}\n",
        "        if latest_only:\n",
        "            for serial in logs_df.serial.unique():\n",
        "                logs_df_by_serial = logs_df[logs_df.serial.str.contains(serial)]\n",
        "                lastest_date = logs_df_by_serial.log_date.unique()[0]\n",
        "                lastest_time = logs_df_by_serial[logs_df_by_serial.log_date.eq(lastest_date)].log_time.unique()[0]\n",
        "                cache[serial] = (lastest_date, lastest_time)\n",
        "\n",
        "            filter_logs_df = pd.DataFrame(columns=logs_df.columns)\n",
        "            for serial, time in cache.items():\n",
        "                filter_df = logs_df[logs_df.serial.str.contains(serial)\n",
        "                                        & logs_df.log_date.eq(time[0])\n",
        "                                        & logs_df.log_time.eq(time[1])]\n",
        "                filter_logs_df = filter_logs_df.append(filter_df)\n",
        "\n",
        "            return filter_logs_df\n",
        "        else:\n",
        "            return logs_df\n",
        "\n",
        "    def GetData_Aux(logs_df, latest_only):\n",
        "        cache = {}\n",
        "        if latest_only:\n",
        "            for serial in logs_df.serial.unique():\n",
        "                logs_df_by_serial = logs_df[logs_df.serial.str.contains(serial)]\n",
        "                lastest_date = logs_df_by_serial.log_date.unique()[0]\n",
        "                lastest_time = logs_df_by_serial[logs_df_by_serial.log_date.eq(lastest_date)].log_time.unique()[0]\n",
        "                cache[serial] = (lastest_date, lastest_time)\n",
        "\n",
        "            filter_logs_df = pd.DataFrame(columns=logs_df.columns)\n",
        "\n",
        "            for serial, time in cache.items():\n",
        "                filter_df = logs_df[logs_df.serial.str.contains(serial)\n",
        "                                        & logs_df.log_date.eq(time[0])]\n",
        "                filter_logs_df = filter_logs_df.append(filter_df)\n",
        "            return filter_logs_df\n",
        "        else:\n",
        "            return logs_df\n",
        "\n",
        "\n",
        "class Drive():\n",
        "    \"\"\"Class definition for pull data from GDrive.\"\"\"\n",
        "    # Authenticate and create the PyDrive client.\n",
        "    auth.authenticate_user()\n",
        "    gauth = GoogleAuth()\n",
        "    gauth.credentials = GoogleCredentials.get_application_default()\n",
        "    drive = GoogleDrive(gauth)\n",
        "    external_colab = True\n",
        "\n",
        "    def date_to_timestamp(year, month, date, time_zone='Asia/Shanghai'):\n",
        "        tz = timezone(time_zone)\n",
        "        timestamp = datetime(year, month, date)\n",
        "        return tz.localize(timestamp).timestamp()\n",
        "\n",
        "    def load_table(table, build_phase, station_pattern,\n",
        "                   config_prefix=None, test_case_pattern=None,\n",
        "                   test_item_pattern=None,\n",
        "                   start_date=Start_Date, last_date=Last_Date):\n",
        "        def get_timestamp(date):\n",
        "            year, month, day = date.split('-')\n",
        "            return Drive.date_to_timestamp(int(year), int(month), int(day)) * 1000\n",
        "\n",
        "        # print('Query from CSV...', end='')\n",
        "        id = None\n",
        "        if table == Table.SENSOR:\n",
        "            id = CSV_FILES[Type][Project].sensor\n",
        "        elif table == Table.LOGS:\n",
        "            id = CSV_FILES[Type][Project].logs\n",
        "        elif table == Table.FACTORY:\n",
        "            id = CSV_FILES[Type][Project].factory\n",
        "\n",
        "        if Drive.external_colab:\n",
        "            csv_file = Drive.drive.CreateFile({'id':id})\n",
        "            data = csv_file.GetContentString()\n",
        "            df = pd.read_csv(StringIO(data))\n",
        "        else:\n",
        "            data = Drive.drive.LoadFile(file_id=id)\n",
        "            df = pd.read_csv(StringIO(data.decode('utf-8')))\n",
        "        df = df[df['build_phase'].str.contains(build_phase)]\n",
        "\n",
        "        if config_prefix:\n",
        "            df = df[df['device_config'].str.match(f'^{config_prefix}')]\n",
        "\n",
        "        start_date_wo_dash = int(start_date.replace('-',''))\n",
        "        last_date_wo_dash = int(last_date.replace('-',''))\n",
        "        start_ts_ms = get_timestamp(start_date)\n",
        "        last_ts_ms = get_timestamp(last_date)\n",
        "        if table == Table.SENSOR:\n",
        "            # Drop the data out of the date conditions\n",
        "            df = df[df['measurement_date_china'] >= int(start_date_wo_dash)]\n",
        "            df = df[df['measurement_date_china'] <= int(last_date_wo_dash)]\n",
        "            # seperate test_case to test_case + test_item\n",
        "            df['test_item'] = df.test_case.apply(lambda x: re.search('TEST_(SENSOR.*|CAM[0-9]IMU[0-9]{1,3}.*|BTS.*)', x).group(1))\n",
        "            df['test_case'] = df.test_case.apply(lambda x: re.search('_(SENSOR[0-9]+|CAM[0-9]IMU[0-9]{1,3}|BTS[0-9]+)_', x).group(1))\n",
        "            df.rename(columns={\n",
        "                'measurement_date_china': 'log_date',\n",
        "                'measurement_time_china': 'log_time'},\n",
        "                inplace=True)\n",
        "            df.drop(columns=['device_config'], inplace=True)\n",
        "\n",
        "        if table == Table.LOGS:\n",
        "            # Drop the data out of the date conditions\n",
        "            df = df[df['log_date'] >= start_date_wo_dash]\n",
        "            df = df[df['log_date'] <= last_date_wo_dash]\n",
        "\n",
        "            # Workaround for BTS log due to no station name included\n",
        "            df['station'].fillna(value=station_pattern, inplace=True)\n",
        "            \n",
        "            df = df[df.station.notna() & df.station.str.contains(station_pattern)]\n",
        "            df['station'] = df.station.apply(lambda x: re.search(f'({station_pattern})', x).group(1))\n",
        "        \n",
        "        if table == Table.FACTORY:\n",
        "            # Drop the data out of the date conditions\n",
        "            df = df[df['start_time_ms'] >= start_ts_ms]\n",
        "            df = df[df['start_time_ms'] <= last_ts_ms]\n",
        "            df = df[df.full_test_name.str.match(test_item_pattern)]\n",
        "            df['test_case'] = df.full_test_name.apply(lambda x: re.search(test_case_pattern, x).group(1))\n",
        "            df['test_item'] = df.full_test_name.apply(lambda x: re.search(test_item_pattern, x).group(2))\n",
        "            df['test_date_time'] = df.start_time_ms.apply(lambda x: strftime('%Y-%m-%dT%H:%M:%S +0000', gmtime(x/1000)))\n",
        "            df.drop(columns=['full_test_name', 'start_time_ms',\n",
        "                             'device_config', 'station'], inplace=True)\n",
        "\n",
        "        # print('Done!')\n",
        "        return df\n",
        "\n",
        "QueryData = Drive.load_table\n",
        "\n",
        "class Station():\n",
        "    \"\"\"Class definition for query station data.\"\"\"\n",
        "    BUILD_PHASE = {\n",
        "        'PROTO': 'PROTO',\n",
        "        'PROTO1.0': 'P1',\n",
        "        'PROTO1.1': 'P2',\n",
        "        'EVT': 'EVT',\n",
        "        'DVT': 'DVT',\n",
        "        'PVT': 'PVT',\n",
        "    }\n",
        "\n",
        "    STATION = {\n",
        "        'WC': f'C_{Project.upper()}_1_WiredCharging',\n",
        "        'NFC': 'C_{Project.upper()}_2a_NfcAggressor',\n",
        "        'CAM': 'C_{Project.upper()}_(.*)_(.*)(Cam|Vcm)',\n",
        "        #'CAM': 'C_{Project.upper()}_(.*)_(.*)(Cam|Vcm)(.*)',\n",
        "        'WLC': 'C_{Project.upper()}_3_WLC',\n",
        "        'SENSOR': 'C_{Project.upper()}_4_Sensor',\n",
        "    }\n",
        "\n",
        "    def wired_charging_station(self) -> pd.DataFrame:\n",
        "        wc_test_df = QueryData(Table.SENSOR, self.BUILD_PHASE[Build],\n",
        "                               self.STATION['WC'])\n",
        "        wc_test_df = wc_test_df[wc_test_df.test_case.str.contains('SENSOR902|SENSOR903')]\n",
        "        wc_test_df = wc_test_df.sort_values(by=['log_date', 'log_time'], ascending=False)\n",
        "        wc_test_df = wc_test_df.drop_duplicates(['serial', 'test_case',\n",
        "                                                 'sensor_name', 'test_item', 'log_time'])\n",
        "        Base.GetDataframeStatus(wc_test_df)\n",
        "\n",
        "        wc_logs_df = QueryData(Table.LOGS, self.BUILD_PHASE[Build],\n",
        "                               self.STATION['WC'])\n",
        "        wc_logs_df = wc_logs_df.sort_values(by=['test_date_time'], ascending=False)\n",
        "        wc_logs_df = wc_logs_df.drop_duplicates(['serial', 'test_case', 'test_date_time'])\n",
        "        wc_logs_df = wc_logs_df[wc_logs_df.test_case.notna() & \\\n",
        "                                wc_logs_df.test_case.str.contains('SENSOR902|SENSOR903')]\n",
        "        wc_logs_df = Base.GetData(wc_logs_df, Latest_Data)\n",
        "\n",
        "        missing_wc_df = Base.CreateMissingDataframe(wc_test_df, wc_logs_df)\n",
        "        wc_df = Base.MergeDataLogs(wc_logs_df, wc_test_df)\n",
        "        wc_df = Base.MergeDataframes(\n",
        "            wc_df, missing_wc_df, ['serial', 'test_case', 'test_item', 'sensor_name'])\n",
        "        wc_df.sort_values(by=['test_item', 'serial'], ascending=False, inplace=True)\n",
        "        wc_df.rename(columns={'val1_std': 'x', 'val2_std': 'y', 'val3_std': 'z'}, inplace=True)\n",
        "        wc_df['full'] = wc_df['serial'] + '_' + wc_df['log_date'].map(str)\n",
        "        return wc_df\n",
        "\n",
        "    def nfc_station(self) -> dict:\n",
        "        test_case_pattern = '^([A-Za-z0-9]+)_'\n",
        "        test_item_pattern = '^CAM[R|F][0-9]{1}(.*)$'\n",
        "        log_item_pattern = 'CAM[F|R][0-9]{1}RAWDARK'\n",
        "\n",
        "        camera_test_df = QueryData(Table.FACTORY, self.BUILD_PHASE[Build],\n",
        "                                   self.STATION['NFC'], None,\n",
        "                                   test_case_pattern, test_item_pattern)\n",
        "        camera_test_df = camera_test_df.sort_values(by=['test_date_time'], ascending=False)\n",
        "        camera_test_df = camera_test_df.drop_duplicates(['serial', 'test_case', 'test_item'])\n",
        "        Base.GetDataframeStatus(camera_test_df)\n",
        "\n",
        "        camera_logs_df = QueryData(Table.LOGS, self.BUILD_PHASE[Build],\n",
        "                                   self.STATION['NFC'])\n",
        "        camera_logs_df = camera_logs_df.sort_values(by=['test_date_time'], ascending=False)\n",
        "        camera_logs_df = camera_logs_df.drop_duplicates(['serial', 'test_case', 'test_date_time'])\n",
        "        camera_logs_df['full'] = camera_logs_df['serial'] + '_' + camera_logs_df['log_date'].map(str)\n",
        "        camera_lum_test_df = camera_test_df[camera_test_df.test_item.notna() & \\\n",
        "                                            camera_test_df.test_item.str.contains('LUMINANCE_WORST')].copy()\n",
        "        # camera_lum_test_df['test_date_time']=camera_lum_test_df['test_date_time'].astype(str)\n",
        "        # drop the inconsistan date time for merging data\n",
        "        camera_lum_test_df.drop(columns=['test_date_time'], inplace=True)\n",
        "\n",
        "        camera_lum_logs_df = camera_logs_df[camera_logs_df.test_case.notna() & \\\n",
        "                                            camera_logs_df.test_case.str.contains(log_item_pattern)].copy()\n",
        "        camera_lum_logs_df.drop(camera_lum_logs_df[camera_lum_logs_df.test_case.str.contains('DARK900') ].index, inplace=True)\n",
        "\n",
        "        columns = camera_lum_logs_df.merge(camera_lum_test_df, how='left',\n",
        "                                           on=['serial', 'test_case', 'build_phase']).columns\n",
        "\n",
        "        cam_test_cases_template = ['CAM{}RAWDARK190', 'CAM{}RAWDARK191']\n",
        "        camera_id = ['Front', 'RearWide', 'RearTele', 'RearUltrawide']\n",
        "\n",
        "        test_case_list = [test_case.format(id) for test_case in cam_test_cases_template for id in camera_id]\n",
        "\n",
        "        merged_df = pd.DataFrame(columns=columns)\n",
        "\n",
        "        process_camera_logs_df = Base.GetData(camera_lum_logs_df, Latest_Data)\n",
        "        for test_case in test_case_list:\n",
        "            merged_df = merged_df.append(Base.ProcessCameraData(camera_lum_test_df,\n",
        "                                                                process_camera_logs_df,\n",
        "                                                                test_case))\n",
        "        merged_df = merged_df.reset_index()\n",
        "        Base.GetDataframeStatus(merged_df)\n",
        "        for idx, row in merged_df.iterrows():\n",
        "            row.test_item = row.test_case[3:5] + '_' + row.test_item\n",
        "            merged_df.iloc[idx] = row\n",
        "\n",
        "        nfc_logs_df = camera_logs_df[camera_logs_df.test_case.notna() \\\n",
        "                          & camera_logs_df.test_case.str.contains('NFC')].copy()\n",
        "        nfc_logs_df = Base.GetData(nfc_logs_df, Latest_Data)\n",
        "        nfc_data_table = nfc_logs_df.append(merged_df)\n",
        "        nfc_logs_df.append(merged_df)\n",
        "        return {\n",
        "            'merged_df': merged_df,\n",
        "            'nfc_logs_df': nfc_logs_df,\n",
        "            'nfc_data_table': nfc_data_table,\n",
        "        }\n",
        "\n",
        "    def camera_station(self) -> dict:\n",
        "        test_case_pattern = '^([A-Za-z0-9]+)_'\n",
        "        test_item_pattern = '^CAM(RearWide|RearTele|RearUltrawide|Front)(.*)$'\n",
        "        log_item_pattern = 'CAM(RearWide|RearTele|RearUltrawide|Front)RAWDARK'\n",
        "\n",
        "        camera_test_df = QueryData(Table.FACTORY, self.BUILD_PHASE[Build],\n",
        "                                   self.STATION['CAM'], None,\n",
        "                                   test_case_pattern, test_item_pattern)\n",
        "        camera_test_df = camera_test_df.sort_values(by=['test_date_time'], ascending=False)\n",
        "        camera_test_df = camera_test_df.drop_duplicates(['serial', 'test_case', 'test_item'])\n",
        "        Base.GetDataframeStatus(camera_test_df)\n",
        "\n",
        "        camera_logs_df = QueryData(Table.LOGS, self.BUILD_PHASE[Build],\n",
        "                                   self.STATION['CAM'])\n",
        "        camera_logs_df = camera_logs_df.sort_values(by=['test_date_time'], ascending=False)\n",
        "        camera_logs_df = camera_logs_df.drop_duplicates(['serial', 'test_case', 'test_date_time'])\n",
        "        camera_logs_df['full'] = camera_logs_df['serial'] + '_' + camera_logs_df['log_date'].map(str)\n",
        "        camera_lum_test_df = camera_test_df[camera_test_df.test_item.notna() & \\\n",
        "                                            camera_test_df.test_item.str.contains('LUMINANCE_WORST')].copy()\n",
        "        # camera_lum_test_df['test_date_time']=camera_lum_test_df['test_date_time'].astype(str)\n",
        "        # drop the inconsistan date time for merging data\n",
        "        camera_lum_test_df.drop(columns=['test_date_time'], inplace=True)\n",
        "\n",
        "        camera_lum_logs_df = camera_logs_df[camera_logs_df.test_case.notna() & \\\n",
        "                                            camera_logs_df.test_case.str.contains(log_item_pattern)].copy()\n",
        "        camera_lum_logs_df.drop(camera_lum_logs_df[camera_lum_logs_df.test_case.str.contains('DARK900') ].index, inplace=True)\n",
        "\n",
        "        camera_lum_logs_df_by_station = camera_lum_logs_df.groupby('station')\n",
        "\n",
        "        columns = camera_lum_logs_df.merge(camera_lum_test_df,\n",
        "                                           how='left',\n",
        "                                           on=['serial',\n",
        "                                               'test_case',\n",
        "                                               'build_phase']).columns\n",
        "\n",
        "        cam_test_cases_template = [\n",
        "            'CAM{}RAWDARK0',   'CAM{}RAWDARK900',\n",
        "            'CAM{}RAWDARK103', 'CAM{}RAWDARK104', 'CAM{}RAWDARK105',\n",
        "            'CAM{}RAWDARK106',\n",
        "            'CAM{}RAWDARK132', 'CAM{}RAWDARK134', 'CAM{}RAWDARK136',\n",
        "            'CAM{}RAWDARK203',\n",
        "            'CAM{}RAWDARK880',\n",
        "        ]\n",
        "\n",
        "        # 2022.09.20(charleslin@) considering remove this later\n",
        "        camera_id_map = {\n",
        "            'Front': 'Front',\n",
        "            'RearTele': 'RearTele',\n",
        "            'RearWide': 'RearWide',\n",
        "            'RearUltraWide': 'RearUltrawide',\n",
        "        }\n",
        "\n",
        "        cam_df = {}\n",
        "        for group_name in camera_lum_logs_df_by_station.groups:\n",
        "            pattern = re.compile(self.STATION['CAM'])\n",
        "            result = pattern.match(group_name)\n",
        "            station_name = result.group(1) # 2b~2e, 2m, 2v\n",
        "            camera_name = result.group(2) # Front/RearWide/...\n",
        "            cam_df[group_name] = {}\n",
        "            if result is not None:\n",
        "                cam_df[group_name]['station'] = station_name\n",
        "                cam_df[group_name]['df'] = pd.DataFrame(columns=columns)\n",
        "                # for station 2m and 2v,  group(2) is empty\n",
        "                if camera_name:\n",
        "                    cam_df[group_name]['id'] = camera_name\n",
        "                    cam_test_cases_list = map(lambda x: x.format(camera_id_map[str(camera_name)]), cam_test_cases_template)\n",
        "\n",
        "                    station_logs_df = camera_lum_logs_df_by_station.get_group(group_name)\n",
        "                    process_camera_logs_df = Base.GetData(station_logs_df, Latest_Data)\n",
        "\n",
        "                    # C_SB3_2m, mmW df\n",
        "                    station_aux_df = camera_lum_logs_df_by_station.get_group(f'C_{Project.upper()}_2m_Cam')\n",
        "                    station_aux_df = station_aux_df[station_aux_df.test_case.str.contains(camera_name)]\n",
        "                    processed_station_aux_df = Base.GetData_Aux(station_aux_df, Latest_Data)\n",
        "                    process_camera_logs_df = pd.concat([process_camera_logs_df, processed_station_aux_df])\n",
        "\n",
        "                    # C_SB3_2v, VCM df\n",
        "                    station_aux_df = camera_lum_logs_df_by_station.get_group(f'C_{Project.upper()}_2v_Vcm')\n",
        "                    station_aux_df = station_aux_df[station_aux_df.test_case.str.contains(camera_name)]\n",
        "                    processed_station_aux_df = Base.GetData_Aux(station_aux_df, Latest_Data)\n",
        "                    process_camera_logs_df = pd.concat([process_camera_logs_df, processed_station_aux_df])\n",
        "\n",
        "            for test_case in cam_test_cases_list:\n",
        "                cam_df[group_name]['df'] = cam_df[group_name]['df'].append(\n",
        "                    Base.ProcessCameraData(camera_lum_test_df,\n",
        "                                           process_camera_logs_df,\n",
        "                                           test_case))\n",
        "            cam_df[group_name]['df'].sort_values(by=['test_item', 'serial'],\n",
        "                                                 ascending=False, inplace=True)\n",
        "        return cam_df\n",
        "\n",
        "    def wireless_charging_station(self) -> pd.DataFrame:\n",
        "        wlc_test_df = QueryData(Table.SENSOR, self.BUILD_PHASE[Build],\n",
        "                                self.STATION['WLC'])\n",
        "        wlc_test_df = wlc_test_df.sort_values(by=['log_date', 'log_time'], ascending=False)\n",
        "        wlc_test_df = wlc_test_df.drop_duplicates(['serial', 'test_case',\n",
        "                                                   'sensor_name', 'test_item',\n",
        "                                                   'log_time'])\n",
        "        wlc_test_df = wlc_test_df[wlc_test_df.test_case.str.contains('SENSOR902|SENSOR903')]\n",
        "        Base.GetDataframeStatus(wlc_test_df)\n",
        "\n",
        "        wlc_logs_df = QueryData(Table.LOGS, self.BUILD_PHASE[Build],\n",
        "                                self.STATION['WLC'])\n",
        "        wlc_logs_df = wlc_logs_df.sort_values(by=['test_date_time'], ascending=False)\n",
        "        wlc_logs_df = wlc_logs_df.drop_duplicates(['serial', 'test_case', 'test_date_time'])\n",
        "        wlc_logs_df = wlc_logs_df[wlc_logs_df.test_case.notna() & \\\n",
        "                                  wlc_logs_df.test_case.str.contains('SENSOR902|SENSOR903')]\n",
        "        wlc_logs_df = Base.GetData(wlc_logs_df, Latest_Data)\n",
        "\n",
        "        missing_wlc_df = Base.CreateMissingDataframe(wlc_test_df, wlc_logs_df)\n",
        "        wlc_df = Base.MergeDataLogs(wlc_logs_df, wlc_test_df)\n",
        "        wlc_df = Base.MergeDataframes(\n",
        "            wlc_df, missing_wlc_df, ['serial', 'test_case', 'test_item', 'sensor_name'])\n",
        "        wlc_df.sort_values(by=['test_item', 'serial'], ascending=False, inplace=True)\n",
        "        wlc_df.rename(columns={'val1_std': 'x', 'val2_std': 'y', 'val3_std': 'z'}, \n",
        "                      inplace=True)\n",
        "        wlc_df['full'] = wlc_df['serial'] + '_' + wlc_df['log_date'].map(str)\n",
        "        return wlc_df\n",
        "\n",
        "    def sensor_station(self) -> pd.DataFrame:\n",
        "        sensor_test_df = QueryData(Table.SENSOR, self.BUILD_PHASE[Build],\n",
        "                                   self.STATION['SENSOR'])\n",
        "        sensor_test_df = sensor_test_df.sort_values(by=['log_date', 'log_time'], ascending=False)\n",
        "        sensor_test_df = sensor_test_df.drop_duplicates(['serial', 'test_case',\n",
        "                                                         'sensor_name', 'test_item',\n",
        "                                                         'log_date', 'log_time'])\n",
        "        sensor_test_df = sensor_test_df[~sensor_test_df.test_case.str.contains('SENSOR902|SENSOR903')]\n",
        "        Base.GetDataframeStatus(sensor_test_df)\n",
        "\n",
        "        sensor_logs_df = QueryData(Table.LOGS, self.BUILD_PHASE[Build],\n",
        "                                   self.STATION['SENSOR'])\n",
        "        sensor_logs_df = sensor_logs_df.sort_values(by=['test_date_time'], \n",
        "                                                    ascending=False)\n",
        "        sensor_logs_df = sensor_logs_df.drop_duplicates(subset=['serial', 'test_case', 'test_date_time'], keep='last')\n",
        "        sensor_logs_df = sensor_logs_df[sensor_logs_df.test_case.notna() & \\\n",
        "                                        sensor_logs_df.test_case.str.contains('SENSOR|BTS')]\n",
        " \n",
        "        if 'SENSOR106' in sensor_logs_df['test_case'].unique():\n",
        "            sensor_logs_mmw_df = sensor_logs_df[sensor_logs_df.test_case.str.contains('SENSOR106')]\n",
        "            sensor_logs_df = sensor_logs_df[~sensor_logs_df.test_case.str.contains('SENSOR106')]\n",
        "            sensor_logs_mmw_df = Base.GetData_Aux(sensor_logs_mmw_df, Latest_Data)\n",
        "            sensor_logs_df = Base.GetData(sensor_logs_df, Latest_Data)\n",
        "            sensor_logs_df = pd.concat([sensor_logs_df, sensor_logs_mmw_df])\n",
        "        else:\n",
        "            sensor_logs_df = Base.GetData(sensor_logs_df, Latest_Data)\n",
        "\n",
        "        missing_df = Base.CreateMissingDataframe(sensor_test_df, sensor_logs_df)\n",
        "        sensor_df = Base.MergeDataLogs(sensor_logs_df, sensor_test_df)\n",
        "        sensor_df = Base.MergeDataframes(\n",
        "            sensor_df, missing_df, ['serial', 'test_case', 'test_item', 'sensor_name'])\n",
        "        sensor_df.sort_values(by=['test_item', 'serial'], ascending=False, inplace=True)\n",
        "        sensor_df.rename(columns={'val1_std': 'x', 'val2_std': 'y', 'val3_std': 'z'}, \n",
        "                         inplace=True)\n",
        "        # sensor_df['log_date'] = sensor_df['log_date'].dropna().astype('int64')\n",
        "        sensor_df['full'] = sensor_df['serial'] + '_' + sensor_df['log_date'].map(str)\n",
        "        return sensor_df\n",
        "\n",
        "QueryStation = Station()\n",
        "\n",
        "@dataclass\n",
        "class SensorPlotly():\n",
        "    \"\"\"Class definition for coex sensor plot.\"\"\"\n",
        "    spec: float\n",
        "    marginal: float\n",
        "    zmax: float\n",
        "    title: str\n",
        "    multiaxes: bool\n",
        "    zmin: float\n",
        "    device_configs: list\n",
        "    hover_x_title: str\n",
        "    axis_settings = dict(tickfont=dict(size=10),\n",
        "                                 tickangle=45,\n",
        "                                 automargin=True)\n",
        "    data_settings = {\n",
        "        True: 'serial',\n",
        "        False: 'full',\n",
        "    }\n",
        "    hover_columns_x = ['serial', 'test_item', 'x', 'device_config',\n",
        "                       'tempature', 'battery', 'test_date_time',\n",
        "                       'result', 'message']\n",
        "    hover_columns_y = ['serial', 'test_item', 'y', 'device_config',\n",
        "                       'tempature', 'battery', 'test_date_time',\n",
        "                       'result', 'message']\n",
        "    hover_columns_z = ['serial', 'test_item', 'z', 'device_config',\n",
        "                       'tempature', 'battery', 'test_date_time',\n",
        "                       'result', 'message']\n",
        "    storage = {}\n",
        "\n",
        "    def _ColorScale(self):\n",
        "        critical = (self.spec - self.zmin) / (self.zmax - self.zmin)\n",
        "        marginal_critical = (self.marginal - self.zmin) / (self.zmax - self.zmin)\n",
        "        return [[0, 'grey'],\n",
        "                [0.0001, 'lightblue'], \n",
        "                [critical, 'royalblue'], \n",
        "                [critical+0.0001, 'Gold'], \n",
        "                [marginal_critical, 'DarkOrange'], \n",
        "                [marginal_critical+0.0001, 'red'], \n",
        "                [1, 'darkred']\n",
        "        ]\n",
        "\n",
        "    def _BuildHeapmap(self, df_x, df_y, df_z, df_hover):\n",
        "        return Heatmap(\n",
        "            z=df_z,\n",
        "            x=df_x,\n",
        "            y=df_y,\n",
        "            xgap=2,\n",
        "            ygap=2,\n",
        "            colorscale=self._ColorScale(),\n",
        "            zmin = self.zmin,\n",
        "            zmax = self.zmax,\n",
        "            hoverinfo='text',\n",
        "            text=df_hover\n",
        "        )\n",
        "\n",
        "    def _HoverInfo(self, x):\n",
        "        output='SN: {}'.format(x[0]) \\\n",
        "             + '<br>TestCase: {}'.format(x[1]) \\\n",
        "             + '<br>{}: {}'.format(self.hover_x_title, x[2]) \\\n",
        "             + '<br>Config: {}'.format(x[3]) \\\n",
        "             + '<br>Temperature (Start/End): {} °C'.format(x[4]) \\\n",
        "             + '<br>Battery (Start/End): {}'.format(x[5]) \\\n",
        "             + '<br>Start Time: {}'.format(x[6])\n",
        "        if isinstance(x[7], str) and 'done' not in x[7]:\n",
        "            output = output + '<br>Result: {}'.format(x[7])\n",
        "        if x[8]:\n",
        "            output = output + '<br>Message: {}'.format(x[8])\n",
        "        return output\n",
        "\n",
        "    def _BuildTraceFigure(self, df):\n",
        "        df_x = df[self.data_settings[Latest_Data]]\n",
        "        df_y = df.test_item\n",
        "        df_z = df.x\n",
        "        hover = df[self.hover_columns_x].apply(lambda x: self._HoverInfo(x), axis=1)\n",
        "        data = [\n",
        "            self._BuildHeapmap(df_x=df[self.data_settings[Latest_Data]],\n",
        "                               df_y=df.test_item, df_z=df.x, df_hover=hover)\n",
        "        ]\n",
        "        layout = Layout(\n",
        "            title= {\n",
        "                'text': self.title,\n",
        "                'xanchor': 'center',\n",
        "                'y': 0.95,\n",
        "                'x': 0.5,\n",
        "            },\n",
        "            xaxis=self.axis_settings,\n",
        "            yaxis=self.axis_settings,\n",
        "            autosize=True,\n",
        "            clickmode='event',\n",
        "        )\n",
        "        return Figure(data=data, layout=layout)\n",
        "\n",
        "    def _BuildTracesFigure(self, df):\n",
        "        hover_x = df[self.hover_columns_x].apply(lambda x: self._HoverInfo(x),\n",
        "                                                 axis=1)\n",
        "        hover_y = df[self.hover_columns_y].apply(lambda x: self._HoverInfo(x),\n",
        "                                                 axis=1)\n",
        "        hover_z = df[self.hover_columns_z].apply(lambda x: self._HoverInfo(x),\n",
        "                                                 axis=1)\n",
        "\n",
        "        fig = subplots.make_subplots(rows=3, cols=1, vertical_spacing=0.08,\n",
        "                                     subplot_titles=('X-Axis',\n",
        "                                                     'Y-Axis',\n",
        "                                                     'Z-Axis'))\n",
        "\n",
        "        # Default all data\n",
        "        x_axis = self._BuildHeapmap(df_x=df[self.data_settings[Latest_Data]],\n",
        "                                    df_y=df.test_item, df_z=df.x,\n",
        "                                    df_hover=hover_x)\n",
        "        y_axis = self._BuildHeapmap(df_x=df[self.data_settings[Latest_Data]],\n",
        "                                    df_y=df.test_item, df_z=df.y,\n",
        "                                    df_hover=hover_y)\n",
        "        z_axis = self._BuildHeapmap(df_x=df[self.data_settings[Latest_Data]],\n",
        "                                    df_y=df.test_item, df_z=df.z,\n",
        "                                    df_hover=hover_z)\n",
        "        fig.add_trace(x_axis, 1, 1)\n",
        "        fig.add_trace(y_axis, 2, 1)\n",
        "        fig.add_trace(z_axis, 3, 1)\n",
        "\n",
        "        fig.update_layout(\n",
        "            title= {\n",
        "                'text': self.title,\n",
        "                'xanchor': 'center',\n",
        "                'y': 0.95,\n",
        "                'x': 0.5,\n",
        "            },\n",
        "            xaxis = dict(self.axis_settings, visible = False),\n",
        "            yaxis = self.axis_settings,\n",
        "            xaxis2 = dict(self.axis_settings, visible = False),\n",
        "            yaxis2 = self.axis_settings,\n",
        "            xaxis3 = self.axis_settings,\n",
        "            yaxis3 = self.axis_settings,\n",
        "            autosize = True,\n",
        "            height = 800,\n",
        "        )\n",
        "        return fig\n",
        "\n",
        "    def _GetDataByDeviceConfig(self, df, device_config):\n",
        "        filtered_df = df[df.device_config.str.match(f'^{device_config}$')]\n",
        "        filtered_hover_x = filtered_df[self.hover_columns_x].apply(lambda x: self._HoverInfo(x), axis=1)\n",
        "        filtered_hover_y = filtered_df[self.hover_columns_y].apply(lambda x: self._HoverInfo(x), axis=1)\n",
        "        filtered_hover_z = filtered_df[self.hover_columns_z].apply(lambda x: self._HoverInfo(x), axis=1)\n",
        "        return [ {'x':[filtered_df[self.data_settings[Latest_Data]],\n",
        "                       filtered_df[self.data_settings[Latest_Data]],\n",
        "                       filtered_df[self.data_settings[Latest_Data]]],\n",
        "                  'y':[filtered_df.test_item,\n",
        "                       filtered_df.test_item,\n",
        "                       filtered_df.test_item],\n",
        "                  'z':[filtered_df.x, filtered_df.y, filtered_df.z],\n",
        "                  'text':[filtered_hover_x, filtered_hover_y, filtered_hover_z]}]\n",
        "\n",
        "    def _AddDevicesConfigSelections(self, df):\n",
        "        \"\"\"Default show all data which the first 3 traces.\"\"\"\n",
        "        buttons = [dict(label='All Configs',\n",
        "                   method='update',\n",
        "                   args=self._GetDataByDeviceConfig(df, '.*'))\n",
        "        ]\n",
        "\n",
        "        for config in self.device_configs:\n",
        "            buttons.append(\n",
        "                dict(label=config,\n",
        "                    method='update',\n",
        "                    args=self._GetDataByDeviceConfig(df, config))\n",
        "            )\n",
        "\n",
        "        self.fig.update_layout(\n",
        "            updatemenus=[\n",
        "                dict(\n",
        "                    active=0,\n",
        "                    buttons=buttons,\n",
        "                    direction='down',\n",
        "                    pad={'r': 10, 't': 10},\n",
        "                    showactive=True,\n",
        "                    x=0.8,\n",
        "                    xanchor='left',\n",
        "                    y=1.25,\n",
        "                    yanchor='top'\n",
        "                ),\n",
        "            ],\n",
        "        )\n",
        "\n",
        "    def Show(self, df, click_event=None):\n",
        "        if self.multiaxes:\n",
        "            self.fig = self._BuildTracesFigure(df)\n",
        "        else:\n",
        "            self.fig = self._BuildTraceFigure(df)\n",
        "        self._AddDevicesConfigSelections(df)\n",
        "        self.fig.show()\n",
        "\n",
        "    @staticmethod\n",
        "    def plot(df, setting, config, title):\n",
        "        device_configs = Base.GetDeviceConfigList(df)\n",
        "        sensor_plotly = SensorPlotly(spec=config['spec'], zmin=config['zmin'],\n",
        "                                     zmax=config['zmax'], marginal=config['marginal'],\n",
        "                                     title=title, multiaxes=setting['multiaxes'],\n",
        "                                     device_configs=device_configs,\n",
        "                                     hover_x_title=config['hover_x_title'])\n",
        "        sensor_plotly.Show(df)\n",
        "\n",
        "    @staticmethod\n",
        "    def compute_diff(test_df, idle_df, multiaxes, columns):\n",
        "        diff_df = pd.DataFrame(columns=columns).drop(\n",
        "            columns=['val1_mean', 'val2_mean', 'val3_mean', 'val1_misc',\n",
        "                     'val2_misc', 'val3_misc'])\n",
        "        if not idle_df.empty and not test_df.empty:\n",
        "            for index, test_row in test_df.iterrows():\n",
        "                idle_rows = idle_df[(\n",
        "                    idle_df[SensorPlotly.data_settings[Latest_Data]].str.contains(test_row[SensorPlotly.data_settings[Latest_Data]])\n",
        "                    & idle_df.test_item.str.contains(test_row.test_item + '_Idle_Reference'))]\n",
        "                if len(idle_rows) > 0:\n",
        "                    idle_row = idle_rows.iloc[0]\n",
        "                    diff_row = test_row.copy()\n",
        "                    diff_row.drop(columns=['val1_mean', 'val2_mean',\n",
        "                                           'val3_mean', 'val1_misc',\n",
        "                                           'val2_misc', 'val3_misc'], inplace=True)\n",
        "\n",
        "                    diff_row.test_item = 'Diff of ' + test_row.loc['test_item'] + '/Idle_Reference'\n",
        "                    diff_row.x = abs(test_row.loc['val1_mean'] - idle_row.loc['val1_mean'])\n",
        "\n",
        "                    if multiaxes:\n",
        "                        diff_row.y = abs(test_row.loc['val2_mean'] - idle_row.loc['val2_mean'])\n",
        "                        diff_row.z = abs(test_row.loc['val3_mean'] - idle_row.loc['val3_mean'])\n",
        "                    diff_df = diff_df.append(diff_row)\n",
        "\n",
        "        return diff_df\n",
        "\n",
        "    @staticmethod\n",
        "    def process(station_df):\n",
        "        try:\n",
        "            serials_filter = dropdown_data_serials.filter_df_by_selected_data(sensor_df.serial)\n",
        "        except NameError:\n",
        "            serials_filter = None\n",
        "\n",
        "        try:\n",
        "            configs_filter = dropdown_data_configs.filter_df_by_selected_data(sensor_df.device_config)\n",
        "        except NameError:\n",
        "            configs_filter = None\n",
        "\n",
        "        without_reference_pattern = 'SENSOR|BTS\\\\d+_(.(?!_Idle_Reference))+$'\n",
        "        test_case_pattern = 'SENSOR|BTS'\n",
        "        settings = [\n",
        "          {\n",
        "            'sensor_name': 'Pressure Sensor',\n",
        "            'multiaxes': False,\n",
        "            'configs': [\n",
        "            {\n",
        "                'type': 'std',\n",
        "                'spec': 0.04,\n",
        "                'marginal': 0.1,\n",
        "                'zmin': 0,\n",
        "                'zmax': 0.14,\n",
        "                'title': 'Pressure Sensor (MEAN_MOVSTD)',\n",
        "                'hover_x_title': 'MEAN_MOVSTD',\n",
        "            },\n",
        "            {\n",
        "                'type': 'mean_idle',\n",
        "                'spec': 0.25,\n",
        "                'marginal': 0.45,\n",
        "                'zmin': 0,\n",
        "                'zmax': 0.7,\n",
        "                'title': 'Pressure Sensor (MEAN_IDLE_DELTA)',\n",
        "                'hover_x_title': 'MEAN_IDLE_DELTA',\n",
        "            }\n",
        "            ],\n",
        "        },\n",
        "        {\n",
        "            'sensor_name': 'ICM45631 Accelerometer-Uncalibrated',\n",
        "            'multiaxes': True,\n",
        "            'configs': [\n",
        "            {\n",
        "                'type': 'std',\n",
        "                'spec': 10,\n",
        "                'marginal': 20,\n",
        "                'zmin': 0,\n",
        "                'zmax': 30,\n",
        "                'title': 'Accelerometer (STD)',\n",
        "                'hover_x_title': 'STD',\n",
        "            },\n",
        "            {\n",
        "                'type': 'mean_idle',\n",
        "                'spec': 5,\n",
        "                'marginal': 15,\n",
        "                'zmin': 0,\n",
        "                'zmax': 20,\n",
        "                'title': 'Accelerometer (MEAN_IDLE_DELTA)',\n",
        "                'hover_x_title': 'MEAN_IDLE_DELTA',\n",
        "            },\n",
        "            ],\n",
        "        },\n",
        "        {\n",
        "            'sensor_name': 'ICM45631 Gyroscope-Uncalibrated',\n",
        "            'multiaxes': True,\n",
        "            'configs': [\n",
        "            {\n",
        "                'type': 'std',\n",
        "                'spec': 300,\n",
        "                'marginal': 500,\n",
        "                'zmin': 0,\n",
        "                'zmax': 800,\n",
        "                'title': 'Gyroscope (STD)',\n",
        "                'hover_x_title': 'STD',\n",
        "            },\n",
        "            {\n",
        "                'type': 'mean_idle',\n",
        "                'spec': 50,\n",
        "                'marginal': 150,\n",
        "                'zmin': 0,\n",
        "                'zmax': 200,\n",
        "                'title': 'Gyroscope (MEAN_IDLE_DELTA)',\n",
        "                'hover_x_title': 'MEAN_IDLE_DELTA',\n",
        "            },\n",
        "            ],\n",
        "        },\n",
        "        {\n",
        "            'sensor_name': 'MMC56X3X Magnetometer 0-Uncalibrated',\n",
        "            'multiaxes': True,\n",
        "            'configs': [\n",
        "                {\n",
        "                'type': 'std',\n",
        "                'spec': 2,\n",
        "                'marginal': 5,\n",
        "                'zmin': 0,\n",
        "                'zmax': 7,\n",
        "                'hover_x_title': 'STD',\n",
        "                'title': 'MMC56X3X Mag0 (STD)',\n",
        "                },\n",
        "                {\n",
        "                'type': 'mean_idle',\n",
        "                'spec': 3,\n",
        "                'marginal': 6,\n",
        "                'zmin': 0,\n",
        "                'zmax': 9,\n",
        "                'hover_x_title': 'MEAN_IDLE_DELTA',\n",
        "                'title': 'MMC56X3X Mag0 (MEAN_IDLE_DELTA)',\n",
        "                },\n",
        "            ],\n",
        "        },\n",
        "        {\n",
        "            'sensor_name': 'MMC56X3X Magnetometer 1-Uncalibrated',\n",
        "            'multiaxes': True,\n",
        "            'configs': [\n",
        "                {\n",
        "                'type': 'std',\n",
        "                'spec': 2,\n",
        "                'marginal': 5,\n",
        "                'zmin': 0,\n",
        "                'zmax': 7,\n",
        "                'hover_x_title': 'STD',\n",
        "                'title': 'MMC56X3X Mag1 (STD)',\n",
        "                },\n",
        "                {\n",
        "                'type': 'mean_idle',\n",
        "                'spec': 3,\n",
        "                'marginal': 6,\n",
        "                'zmin': 0,\n",
        "                'zmax': 9,\n",
        "                'hover_x_title': 'MEAN_IDLE_DELTA',\n",
        "                'title': 'MMC56X3X Mag1 (MEAN_IDLE_DELTA)',\n",
        "                },\n",
        "            ],\n",
        "            },\n",
        "            {\n",
        "                'sensor_name': 'MLX90632 FIR Temperature',\n",
        "                'multiaxes': False,\n",
        "                'configs': [\n",
        "                {\n",
        "                    'type': 'std',\n",
        "                    'spec': 0.04,\n",
        "                    'marginal': 0.1,\n",
        "                    'zmin': 0,\n",
        "                    'zmax': 0.14,\n",
        "                    'title': 'BTS Sensor (OBJ_TEMP_STD)',\n",
        "                    'hover_x_title': 'OBJ_TEMP_TD',\n",
        "                },\n",
        "                {\n",
        "                    'type': 'std',\n",
        "                    'spec': 0.04,\n",
        "                    'marginal': 0.1,\n",
        "                    'zmin': 0,\n",
        "                    'zmax': 0.14,\n",
        "                    'title': 'BTS Sensor (AMB_TEMP_STD)',\n",
        "                    'hover_x_title': 'AMB_TEMP_STD',\n",
        "                }\n",
        "                ],\n",
        "            },\n",
        "        ]\n",
        "\n",
        "        for setting in settings:\n",
        "            data_filter = station_df.sensor_name.str.contains(setting['sensor_name']) \\\n",
        "                & station_df.test_case.str.contains(test_case_pattern)\n",
        "            if serials_filter is not None:\n",
        "                data_filter = data_filter & serials_filter\n",
        "            if configs_filter is not None:\n",
        "                data_filter = data_filter & configs_filter\n",
        "\n",
        "            for config in setting['configs']:\n",
        "                test_df = station_df[data_filter & station_df.test_item.str.contains(without_reference_pattern)]\n",
        "                if test_df.empty:\n",
        "                    raise TypeError(\"dataframe empty, please check sensor name: '\\s'\",\n",
        "                                    setting['sensor_name'])\n",
        "\n",
        "                if config['type'] == 'std':\n",
        "                    if 'MLX90632' in setting['sensor_name']:\n",
        "                      if 'AMB' in config['title']:\n",
        "                        #test_df.rename(columns={'x': 'val1_std'}, inplace=True)\n",
        "                        test_df.rename(columns={'val2_std': 'x'}, inplace=True)\n",
        "                    \n",
        "                    title = config['title']\n",
        "                    SensorPlotly.plot(test_df, setting, config, title)\n",
        "                    SensorPlotly.storage[title] = test_df\n",
        "\n",
        "                else:\n",
        "                    idle_df = station_df[data_filter & station_df.test_item.str.contains('Idle_Reference')]\n",
        "\n",
        "                    diff_df = SensorPlotly.compute_diff(test_df, idle_df,\n",
        "                                                        setting['multiaxes'],\n",
        "                                                        station_df.columns)\n",
        "                    if len(diff_df) > 0:\n",
        "                        title = config['title']\n",
        "                        SensorPlotly.plot(diff_df, setting, config, title)\n",
        "                        SensorPlotly.storage[title] = diff_df\n",
        "\n",
        "                        # Turn sensor summary to csv file\n",
        "                        filename = datetime.now().strftime('%Y%m%d_' + 'sensor_summary.csv')\n",
        "                        diff_df = diff_df.append(test_df)\n",
        "                        diff_df = diff_df[['serial', 'test_date_time',\n",
        "                                           'device_config', 'sensor_name',\n",
        "                                           'test_item', 'x', 'y', 'z']]\n",
        "                        diff_df.to_csv(filename, mode='a')\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class CameraDarkFramePlotly(SensorPlotly):\n",
        "    \"\"\"Class definition for coex camera plot.\"\"\"\n",
        "    height: int = 900\n",
        "    width: int = 1600\n",
        "    hover_x_title: str = 'DELTA (IDLE)'\n",
        "    average_pattern = 'DARK[0-9]{1,3}_LUMINANCE_WORST_AVG'\n",
        "    delta_pattern = 'DARK[0-9]{1,3}_LUMINANCE_WORST_DELTA'\n",
        "    max_pattern = 'DARK[0-9]{1,3}_LUMINANCE_WORST_MAX'\n",
        "    min_pattern = 'DARK[0-9]{1,3}_LUMINANCE_WORST_MIN'\n",
        "    hover_columns = ['serial', 'test_item', 'value', 'device_config',\n",
        "                     'tempature', 'battery', 'test_date_time',\n",
        "                     'result', 'message']\n",
        "\n",
        "    def _ColorScale(self):\n",
        "        length = self.zmax - self.zmin\n",
        "        spec_position = (self.spec - self.zmin)/length\n",
        "        zero_position = (0 - self.zmin)/length\n",
        "        return [[0, 'lightgreen'],\n",
        "                [zero_position, 'lightblue'],\n",
        "                [spec_position, 'darkblue'],\n",
        "                [spec_position+0.0001, 'red'],\n",
        "                [1, 'darkred']\n",
        "        ]\n",
        "\n",
        "    def _HoverInfo(self, x):\n",
        "        output='SN: {}'.format(x[0]) \\\n",
        "             + '<br>TestCase: {}'.format(x[1].split('_')[0]) \\\n",
        "             + '<br>{}: {}'.format(self.hover_x_title, x[2]) \\\n",
        "             + '<br>Config: {}'.format(x[3]) \\\n",
        "             + '<br>Temperature (Start/End): {} °C'.format(x[4]) \\\n",
        "             + '<br>Battery (Start/End): {}'.format(x[5]) \\\n",
        "             + '<br>Start Time: {}'.format(x[6])\n",
        "\n",
        "        if isinstance(x[7], str) and 'pass' not in x[7]:\n",
        "            output = output + '<br>Result: {}'.format(x[7])\n",
        "            output = output + '<br>Message: {}'.format(x[8])\n",
        "        return output\n",
        "\n",
        "    def _BuildTracesFigure(self, df):\n",
        "        average_df = df[df.test_item.str.contains(self.average_pattern)]\n",
        "        #average_df.test_item = average_df.test_item.str.replace('_LUMINANCE_WORST_AVG', '')\n",
        "        average_hover_df = average_df[self.hover_columns].apply(lambda x: self._HoverInfo(x), axis=1)\n",
        "        average = self._BuildHeapmap(average_df[self.data_settings[Latest_Data]],\n",
        "                                     average_df.test_item, average_df.value, average_hover_df)\n",
        "        delta_df = df[df.test_item.str.contains(self.delta_pattern)]\n",
        "        #delta_df.test_item = delta_df.test_item.str.replace('_LUMINANCE_WORST_DELTA', '')\n",
        "        delta_hover_df = delta_df[self.hover_columns].apply(lambda x: self._HoverInfo(x), axis=1)\n",
        "        delta = self._BuildHeapmap(delta_df[self.data_settings[Latest_Data]],\n",
        "                                   delta_df.test_item, delta_df.value, delta_hover_df)\n",
        "        max_df = df[df.test_item.str.contains(self.max_pattern)]\n",
        "        #max_df.test_item = max_df.test_item.str.replace('_LUMINANCE_WORST_MAX', '')\n",
        "        max_hover_df = max_df[self.hover_columns].apply(lambda x: self._HoverInfo(x), axis=1)\n",
        "        cmax = self._BuildHeapmap(max_df[self.data_settings[Latest_Data]],\n",
        "                                  max_df.test_item, max_df.value, max_hover_df)\n",
        "        min_df = df[df.test_item.str.contains(self.min_pattern)]\n",
        "        #min_df.test_item = min_df.test_item.str.replace('_LUMINANCE_WORST_MIN', '')\n",
        "        min_hover_df = min_df[self.hover_columns].apply(lambda x: self._HoverInfo(x), axis=1)\n",
        "        cmin = self._BuildHeapmap(min_df[self.data_settings[Latest_Data]],\n",
        "                                  min_df.test_item, min_df.value, min_hover_df)\n",
        "\n",
        "        fig = subplots.make_subplots(rows=4, cols=1, vertical_spacing=0.07,\n",
        "                                     subplot_titles=('Average', 'Delta',\n",
        "                                                     'Max', 'Min')\n",
        "                                    )\n",
        "        fig.add_trace(average, 1, 1)\n",
        "        fig.add_trace(delta, 2, 1)\n",
        "        fig.add_trace(cmax, 3, 1)\n",
        "        fig.add_trace(cmin, 4, 1)\n",
        "        fig.update_layout(\n",
        "            title= {\n",
        "                'text': self.title,\n",
        "                'xanchor':'center',\n",
        "                'y':0.95,\n",
        "                'x':0.5,\n",
        "            },\n",
        "            xaxis = dict(self.axis_settings,visible = False),\n",
        "            yaxis = self.axis_settings,\n",
        "            xaxis2 = dict(self.axis_settings,visible = False),\n",
        "            yaxis2 = self.axis_settings,\n",
        "            xaxis3 = dict(self.axis_settings,visible = False),\n",
        "            yaxis3 = self.axis_settings,\n",
        "            xaxis4 = dict(self.axis_settings,visible = True),\n",
        "            yaxis4 = self.axis_settings,\n",
        "            autosize=True,\n",
        "        )\n",
        "        return fig\n",
        "\n",
        "    def _GetDataByDeviceConfig(self, df, device_config):\n",
        "        filtered_df = df[df.device_config.str.match(f'^{device_config}$')]\n",
        "        filtered_average_df = filtered_df[filtered_df.test_item.str.contains(\n",
        "            self.average_pattern)]\n",
        "        average_hover_df = filtered_average_df[self.hover_columns].apply(\n",
        "            lambda x: self._HoverInfo(x), axis=1)\n",
        "\n",
        "        filtered_delta_df = filtered_df[filtered_df.test_item.str.contains(\n",
        "            self.delta_pattern)]\n",
        "        delta_hover_df = filtered_delta_df[self.hover_columns].apply(\n",
        "            lambda x: self._HoverInfo(x), axis=1)\n",
        "\n",
        "        filtered_max_df = filtered_df[filtered_df.test_item.str.contains(\n",
        "            self.max_pattern)]\n",
        "        max_hover_df = filtered_max_df[self.hover_columns].apply(\n",
        "            lambda x: self._HoverInfo(x), axis=1)\n",
        "\n",
        "        filtered_min_df = filtered_df[filtered_df.test_item.str.contains(\n",
        "            self.min_pattern)]\n",
        "        min_hover_df = filtered_min_df[self.hover_columns].apply(\n",
        "            lambda x: self._HoverInfo(x), axis=1)\n",
        "\n",
        "        return [ {'x':[filtered_average_df[self.data_settings[Latest_Data]],\n",
        "                       filtered_delta_df[self.data_settings[Latest_Data]],\n",
        "                       filtered_max_df[self.data_settings[Latest_Data]],\n",
        "                       filtered_min_df[self.data_settings[Latest_Data]]],\n",
        "                  'y':[filtered_average_df.test_item, filtered_delta_df.test_item,\n",
        "                       filtered_max_df.test_item, filtered_min_df.test_item],\n",
        "                  'z':[filtered_average_df.value, filtered_delta_df.value,\n",
        "                       filtered_max_df.value, filtered_min_df.value],\n",
        "                  'text':[average_hover_df, delta_hover_df,\n",
        "                          max_hover_df, min_hover_df]}\n",
        "        ]\n",
        "\n",
        "        def _AddDevicesConfigSelections(self, df):\n",
        "            buttons = [dict(label='All Configs',\n",
        "                            method='update',\n",
        "                            args=self._GetDataByDeviceConfig(df, '.*'))\n",
        "            ]\n",
        "\n",
        "            for config in self.device_configs:\n",
        "                buttons.append(\n",
        "                    dict(label=config,\n",
        "                        method='update',\n",
        "                        args=self._GetDataByDeviceConfig(df, config))\n",
        "                )\n",
        "\n",
        "            self.fig.update_layout(\n",
        "                updatemenus=[\n",
        "                    dict(\n",
        "                        active=0,\n",
        "                        buttons=buttons,\n",
        "                        direction='down',\n",
        "                        pad={'r': 10, 't': 10},\n",
        "                        showactive=True,\n",
        "                        x=0.8,\n",
        "                        xanchor='left',\n",
        "                        y=1.25,\n",
        "                        yanchor='top'\n",
        "                    ),\n",
        "                ],\n",
        "            )\n",
        "\n",
        "    def Show(self, df):\n",
        "        self.fig = self._BuildTracesFigure(df)\n",
        "        self._AddDevicesConfigSelections(df)\n",
        "        self.fig.show()\n",
        "\n",
        "\n",
        "class NFCPlotly(SensorPlotly):\n",
        "    \"\"\"Class definition for coex nfc plot.\"\"\"\n",
        "    def _ColorScale(self):\n",
        "        critical = (self.spec - self.zmin) / (self.zmax - self.zmin)\n",
        "        return [[0, 'grey'],\n",
        "                [0.0001, 'lightblue'],\n",
        "                [critical, 'darkblue'],\n",
        "                [critical+0.0001, 'red'],\n",
        "                [1, 'darkred']\n",
        "        ]\n",
        "\n",
        "    def _BuildTraceFigure(self, df):\n",
        "        df_x = df[self.data_settings[Latest_Data]]\n",
        "        df_y = df.test_item\n",
        "        df_z = df.x\n",
        "        hover = df[self.hover_columns_x].apply(lambda x: self._HoverInfo(x),\n",
        "                                               axis=1)\n",
        "        data = [self._BuildHeapmap(df_x=df[self.data_settings[Latest_Data]],\n",
        "                                   df_y=df.test_item, df_z=df.x,\n",
        "                                   df_hover=hover)]\n",
        "        layout = Layout(\n",
        "            title= {'text': self.title,\n",
        "                    'xanchor':'center',\n",
        "                    'y':0.95,\n",
        "                    'x':0.5,\n",
        "            },\n",
        "            xaxis=self.axis_settings,\n",
        "            yaxis=self.axis_settings,\n",
        "            autosize=True,\n",
        "            clickmode='event')\n",
        "        return Figure(data=data, layout=layout)\n",
        "\n",
        "    def Show(self, df, click_event=None):\n",
        "        self.fig = self._BuildTraceFigure(df)\n",
        "        self.fig.show()\n",
        "\n",
        "    def plots(self):\n",
        "        df = nfc_df['nfc_logs_df'].copy()\n",
        "        df['x'] = df['result']\n",
        "        df['test_item'] = df['test_case']\n",
        "        df['x'].replace(['PASS'], 0, inplace=True)\n",
        "        df['x'].replace(['FAIL'], 1, inplace=True)\n",
        "        df = df.sort_values(by=['serial', 'test_item'], ascending=False)\n",
        "        self.Show(df)\n",
        "\n",
        "\n",
        "class DropdownMenu():\n",
        "    \"\"\"Class definition for sensor filter.\"\"\"\n",
        "    def __init__(self, type_name, data):\n",
        "        self.selected_data = []\n",
        "        self.request_cam_data = {}\n",
        "        self.type_name = type_name\n",
        "        self.dropdown_data = {type_name: data}\n",
        "\n",
        "    def show_readme(self):\n",
        "        html = '''<div>\n",
        "                    <h3>This field is to select specific device {item} to plot data.<br>\n",
        "                    If there is selected {item}, then it will plot data of selected {item}.<br>\n",
        "                    Otherwise, it will plot all data in the next cell.\n",
        "                    </h3><br></div>'''\n",
        "\n",
        "        return display(HTML(html.format(item=self.type_name)))\n",
        "\n",
        "    def render_multiple_dropdown(self):\n",
        "        optionsList = pd.Series(self.dropdown_data[self.type_name])\n",
        "        callback_name = label = param_name = self.type_name\n",
        "        val=''.join(self.request_cam_data)\n",
        "        javascript_out = '''columnid_list = ['DUTR_TEST_NAME', 'DUTR_DEVICE_CONFIG', 'DUTR_BUILD_PHASE']\n",
        "                            param_list = ['test_names', 'device_configs', 'build_phases']\n",
        "                            var my_js_data = {};\n",
        "                            const listenerChannel = new BroadcastChannel('channel');\n",
        "                            listenerChannel.onmessage = (msg) => {\n",
        "                            my_js_data = msg.data;\n",
        "                            for(columnid in columnid_list){\n",
        "                                var optionList = my_js_data[columnid_list[cvolumnid]]; \n",
        "                                var optionStr = '';\n",
        "                                for (x in optionList){\n",
        "                                optionStr += '<option value ='+ optionList[x] +'>' + optionList[x] +'</option>'}\n",
        "                                $('#'+param_list[columnid]).empty().trigger(\"change\");\n",
        "                                document.getElementById(param_list[columnid]).innerHTML = optionStr;\n",
        "                            }\n",
        "                            }'''\n",
        "        display(Javascript(javascript_out))\n",
        "        html = \"\"\n",
        "        html += '''<link href=\"https://cdnjs.cloudflare.com/ajax/libs/select2/4.0.4/css/select2.min.css\" rel=\"stylesheet\"/>\n",
        "                <script src=\"https://ajax.googleapis.com/ajax/libs/jquery/2.0.0/jquery.min.js\"></script>\n",
        "                <script src=\"https://cdnjs.cloudflare.com/ajax/libs/select2/4.0.4/js/select2.min.js\"></script>'''\n",
        "        html += \"\"\"<br><br><br><br><br>\"\"\"\n",
        "        html += \"<div id = '\"+param_name+\"Div'>\"\n",
        "        html += \"<label style='font-size: 15px; font-weight: bold; margin-right: 8px; font-family: inherit;'> \"+label+\": </label>\"\n",
        "        html += \"<select id = '\"+param_name+\"' multiple> </select>\"\n",
        "        html += \"</div><br>\"\n",
        "        html += '''<script>'''\n",
        "        html += '''$(document).ready(function(){'''\n",
        "        html += \"var onload_options = JSON.stringify({});\".format(optionsList.to_json())\n",
        "        html += '''var curr_val = \"'''+val+'''\";\n",
        "                onload_options = onload_options.replace(\"'\",\"\\'\");\n",
        "                onload_options = JSON.parse(onload_options);\n",
        "                var default_options = '';\n",
        "                for (x in onload_options){\n",
        "                    default_options += '<option value ='+ onload_options[x] +'>' + onload_options[x] +'</option>';}\n",
        "                document.getElementById(\"'''+param_name+'''\").innerHTML = default_options;\n",
        "                $('#'''+param_name+'''').val(curr_val.split(\",\")).trigger('change');\n",
        "                $('#'''+param_name+'''').on(\"change\", function() {\n",
        "                    if($('#'''+param_name+'''').val() == null) var selectedVal = \"\";\n",
        "                    else var selectedVal = $(this).val().toString();\n",
        "                    var param_name = document.querySelector('#'''+param_name+'''').id;\n",
        "                    google.colab.kernel.invokeFunction(\"'''+callback_name+'''\", [selectedVal, param_name], {});\n",
        "                });'''\n",
        "        html += \"$('#\"+param_name+\"').select2({\"\n",
        "        html +=\"placeholder: 'Select \"+label+\"', width: '800px' }); }); </script>\"\n",
        "        return display(HTML(html))\n",
        "\n",
        "    def set_selected_data(self, newVal, param_name):\n",
        "        self.selected_data = newVal.split(',') if newVal else []\n",
        "\n",
        "    def set_selected_cam_data(self, newVal, param_name):\n",
        "        self.request_cam_data[param_name] = newVal.split(',') if newVal else []\n",
        "\n",
        "    def get_selected_data(self):\n",
        "        return self.selected_data\n",
        "\n",
        "    def get_selected_cam_data(self):\n",
        "        return self.request_cam_data\n",
        "\n",
        "    def filter_df_by_selected_data(self, df):\n",
        "        return df.isin(self.selected_data) if self.selected_data else None\n",
        "\n",
        "    def filter_df_by_selected_cam_data(self, df, param_name):\n",
        "        return df.serial.isin(self.request_cam_data[param_name]) \\\n",
        "            if self.request_cam_data[param_name] else None\n",
        "\n",
        "    def register_callback(self):\n",
        "        output.register_callback(self.type_name, self.set_selected_data)\n",
        "\n",
        "    def register_cam_callback(self):\n",
        "        output.register_callback(self.type_name, self.set_selected_cam_data)\n",
        "\n",
        "\n",
        "class Dropdowntable():\n",
        "    \"\"\"Class definition for sensor table filter.\"\"\"\n",
        "    callback_name = 'table.on_change'\n",
        "    master_dropdown_data = SensorPlotly.storage \\\n",
        "        if SensorPlotly.storage is not None else {}\n",
        "    request_table = ''\n",
        "    request_test_item = ''\n",
        "    \n",
        "    @staticmethod\n",
        "    def show_readme():\n",
        "        html = '''<div>\n",
        "                    <h3>\n",
        "                        This field is to select specific table and its test_item.<br>\n",
        "                        You can get mean, min, max value.\n",
        "                    </h3>\n",
        "                    <br>\n",
        "                    </div>'''\n",
        "\n",
        "        return display(HTML(html))\n",
        "\n",
        "    def render_multiple_dropdown(self):\n",
        "        param_name1 = 'request_table'\n",
        "        label1 = 'Table'\n",
        "        param_name2 = 'request_test_item'\n",
        "        label2 = 'Test item'\n",
        "        optionsList = list(self.master_dropdown_data.keys())\n",
        "        itemOptionsList = list(\n",
        "            self.master_dropdown_data[self.request_table].test_item.unique()) if self.request_table else []\n",
        "        val = self.request_table\n",
        "        html = ''\n",
        "        html += '''<link href=\"https://cdnjs.cloudflare.com/ajax/libs/select2/4.0.4/css/select2.min.css\" rel=\"stylesheet\"/>\n",
        "                <script src=\"https://ajax.googleapis.com/ajax/libs/jquery/2.0.0/jquery.min.js\"></script>\n",
        "                <script src=\"https://cdnjs.cloudflare.com/ajax/libs/select2/4.0.4/js/select2.min.js\"></script>'''\n",
        "        html += \"<div id = '\"+param_name1+\"Div' height = '100%'>\"\n",
        "        html += \"<label style='font-size: 15px; font-weight: bold; margin-right: 8px; font-family: inherit;'> \"+label1+\": </label>\"\n",
        "        html += \"<select id = '\"+param_name1+\"'> </select>\"\n",
        "        html += \"</div><br>\"\n",
        "        html += \"<div id = '\"+param_name2+\"Div'>\"\n",
        "        html += \"<label style='font-size: 15px; font-weight: bold; margin-right: 8px; font-family: inherit;'> \"+label2+\": </label>\"\n",
        "        html += \"<select id = '\"+param_name2+\"'> </select>\"\n",
        "        html += \"</div><br>\"\n",
        "        html += \"\"\"<br><br><br><br><br><br><br><br><br><br><br><br>\"\"\"\n",
        "        html += '''<script>'''\n",
        "        html += '''$(document).ready(function(){'''\n",
        "        html += \"var onload_options = {};\".format(optionsList)\n",
        "        html += '''var curr_val = \"'''+val+'''\";\n",
        "                var default_options = '';\n",
        "                for (x in onload_options){\n",
        "                    default_options += '<option value =' + onload_options[x] + '>' + onload_options[x] + '</option>';}\n",
        "                document.getElementById(\"'''+param_name1+'''\").innerHTML = default_options;\n",
        "\n",
        "                $('#'''+param_name1+'''').val(curr_val.split(\",\")).trigger('change');\n",
        "                $('#'''+param_name1+'''').on(\"change\", function() {\n",
        "                    if($('#'''+param_name1+'''').val() == null) var selectedVal = \"\";\n",
        "                    else var selectedVal = $(this).context.options[$(this).context.selectedIndex].innerText;\n",
        "                    var param_name = document.querySelector('#'''+param_name1+'''').id;\n",
        "                    google.colab.kernel.invokeFunction(\"'''+self.callback_name+'''\", [selectedVal, param_name], {});\n",
        "                });\n",
        "                \n",
        "                $('#'''+param_name2+'''').val(curr_val.split(\",\")).trigger('change');\n",
        "                $('#'''+param_name2+'''').on(\"change\", function() {\n",
        "                    if($('#'''+param_name2+'''').val() == null) var selectedVal = \"\";\n",
        "                    else var selectedVal = $(this).context.options[$(this).context.selectedIndex].innerText;\n",
        "                    var param_name = document.querySelector('#'''+param_name2+'''').id;\n",
        "                    google.colab.kernel.invokeFunction(\"'''+self.callback_name+'''\", [selectedVal, param_name], {});\n",
        "                });\n",
        "                '''\n",
        "        html += \"$('#\"+param_name1+\"').select2({\"\n",
        "        html +=\"placeholder: 'Select \"+label1+\"', width: '800px' });\"\n",
        "        html += \"$('#\"+param_name2+\"').select2({\"\n",
        "        html +=\"placeholder: 'Select \"+label2+\"', width: '800px' }); }); </script>\"\n",
        "        return display(HTML(html))\n",
        "\n",
        "    def show_table(self, newVal, param_name):\n",
        "        if param_name == 'request_table':\n",
        "            self.request_table = newVal\n",
        "            itemOptionsList = list(\n",
        "                self.master_dropdown_data[self.request_table].test_item.unique()) if self.request_table else []\n",
        "            js = ''\n",
        "            js += 'var onload_item_options = {};'.format(itemOptionsList)\n",
        "            js += '''\n",
        "            var default_options = '';\n",
        "            for (x in onload_item_options){\n",
        "            default_options += '<option value =' + onload_item_options[x] + '>' + onload_item_options[x] + '</option>';}\n",
        "            document.getElementById('request_test_item').innerHTML = default_options;\n",
        "            '''\n",
        "            display(Javascript(js))\n",
        "        else:\n",
        "            self.request_test_item = newVal\n",
        "\n",
        "    def register_callback(self):\n",
        "        output.register_callback(self.callback_name, self.show_table)\n",
        "\n",
        "    def output_table(self):\n",
        "        if self.request_table and self.request_test_item:\n",
        "            request_df = SensorPlotly.storage[self.request_table]\n",
        "            reqest_item_table = request_df[request_df.test_item.str.contains(self.request_test_item)]\n",
        "            reqest_item_table = reqest_item_table.drop(\n",
        "                columns=['sensor_name', 'project', 'build_phase',\n",
        "                         'device_config', 'station','battery', 'filename',\n",
        "                         'gs_path', 'log_date', 'log_time','time_std',\n",
        "                         'test_case', 'test_item', 'elapsed',\n",
        "                         'message','time_mean', 'result'])\n",
        "            x_list = reqest_item_table.x.to_list()\n",
        "            print(f'min_x: {min(x_list)}, max_x: {max(x_list)}, \\\n",
        "                    mean_x: {np.mean(x_list)}, std_x: {np.std(x_list)}')\n",
        "            y_list = reqest_item_table.y.to_list()\n",
        "            print(f'min_y: {min(y_list)}, max_y: {max(y_list)}, \\\n",
        "                    mean_y: {np.mean(y_list)}, std_y: {np.std(y_list)}')\n",
        "            z_list = reqest_item_table.z.to_list()\n",
        "            print(f'min_z: {min(z_list)}, max_z: {max(z_list)}, \\\n",
        "                    mean_z: {np.mean(z_list)}, std_z: {np.std(z_list)}')\n",
        "        else:\n",
        "            print('Please select a table and test item.')\n",
        "\n",
        "\n",
        "class Summary():\n",
        "    \"\"\"Class definition for summary data table.\"\"\"\n",
        "    def print_data_table(df) -> pd.DataFrame:\n",
        "        devices_count = df.serial.nunique()\n",
        "        print(f'Tested devices: {devices_count}')\n",
        "        max_date = max(df[df['log_date'].notna()].log_date.astype(int))\n",
        "        min_date = min(df[df['log_date'].notna()].log_date.astype(int))\n",
        "        print(f'Test period: {min_date} - {max_date}')\n",
        "        return data_table.DataTable(df, num_rows_per_page=10,\n",
        "                                    max_columns=40, max_rows=5000)\n",
        "\n",
        "    def print_fail_data_table(df) -> pd.DataFrame:\n",
        "        fail_df = df[['serial', 'device_config', 'test_case',\n",
        "                      'test_date_time', 'result', 'message',\n",
        "                      'battery',\t'tempature']]\n",
        "        fail_df = fail_df[fail_df['result'].str.contains('FAIL', na=False)]\n",
        "        fail_df = fail_df.drop_duplicates(subset=['serial', 'device_config',\n",
        "                                                  'test_date_time', 'test_case',\n",
        "                                                  'message'])\n",
        "        print('Total fail:', len(fail_df))\n",
        "        return data_table.DataTable(fail_df, num_rows_per_page=10,\n",
        "                                    max_columns=40, max_rows=5000)\n",
        "\n",
        "    def check_fail_summary(df) -> pd.DataFrame:\n",
        "        if fail_summay:\n",
        "            return Summary.print_fail_data_table(df)\n",
        "        else:\n",
        "            return Summary.print_data_table(df)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Pull sensor data from GCS\n",
        "\"\"\"\n",
        "class Gspull():\n",
        "    \"\"\"Class definition for pull data from GCS.\"\"\"\n",
        "    GSUTIL_URL = 'https://cloud.google.com/storage/docs/gsutil_install'\n",
        "    UNZIP = '/usr/bin/unzip'\n",
        "    RM = '/bin/rm'\n",
        "\n",
        "    def _shell(cmd, errmsg=None):\n",
        "        \"\"\"Run a shell command and check for error.\n",
        "\n",
        "        Args:\n",
        "            cmd: Shell command to run.\n",
        "            errmsg: Non-standard error message.\n",
        "\n",
        "        Returns:\n",
        "            Ouput of the command.\n",
        "\n",
        "        Raises:\n",
        "            Exception if non-zero return code.\n",
        "        \"\"\"\n",
        "        logging.debug('|D| %s', cmd)\n",
        "        out, ret = pexpect.run(cmd, withexitstatus=True)\n",
        "        if ret:\n",
        "            if errmsg is None:\n",
        "                errmsg = '|E| Command: \"{}\" -> {}'.format(cmd, out)\n",
        "            logging.error(errmsg)\n",
        "            raise Exception(errmsg)\n",
        "        return out.decode('utf-8')\n",
        "\n",
        "\n",
        "    def gs_dataframe(args):\n",
        "        \"\"\"Create dataframes of GCS buckets from infile.\n",
        "\n",
        "        Args:\n",
        "            args: User arguments.\n",
        "\n",
        "        Returns:\n",
        "            Dataframe of GCS bucket ids and filenames.\n",
        "        \"\"\"\n",
        "        # Create output directory\n",
        "        outdir = Path(args.outdir) #.expanduser().resolve()\n",
        "        outdir.mkdir(parents=True, exist_ok=True)\n",
        "        # Read xlsx/csv input file of column (gs_path, filename)\n",
        "        inf = Path(args.infile).expanduser().resolve()\n",
        "        col_names = ['gs_path', 'filename']\n",
        "        if inf.suffix == '.xlsx':\n",
        "            dfr = pd.read_excel(inf, usecols=col_names, sheet_name=args.sheet)\n",
        "        else:\n",
        "            dfr = pd.read_csv(inf, usecols=col_names)\n",
        "        # Make full-path filename\n",
        "        joinpath = lambda x: str(outdir.joinpath(x))\n",
        "        dfr['filename'] = dfr['filename'].apply(joinpath)\n",
        "        # Selective pulls based on user arguments\n",
        "        # -x/-y to exclude/include pulls\n",
        "        mask = False\n",
        "        contains = dfr.filename.str.contains\n",
        "        if args.exclude:\n",
        "            mask |=  contains('|'.join(args.exclude.split(',')))\n",
        "        if args.include:\n",
        "            mask |= ~contains('|'.join(args.include.split(',')))\n",
        "        if not isinstance(mask, bool):\n",
        "            dfr.drop(dfr[mask].index, inplace=True)\n",
        "        # -l to limit number of files to pull\n",
        "        if args.limit:\n",
        "            dfr = dfr.head(args.limit)\n",
        "        return dfr\n",
        "\n",
        "\n",
        "    def gs_worker(gs_path, filename, keep=True, test=False):\n",
        "        \"\"\"Worker (for multiprocessin) to pull and unzip files from GCS.\n",
        "\n",
        "        Args:\n",
        "            gs_path: GCS bucket id.\n",
        "            filename: File name for the pulled file.\n",
        "            keep: True to keep the zip file pulled.\n",
        "            test: True to test integrity of the gz filee without extracting them.\n",
        "\n",
        "        Returns:\n",
        "            Full path of the unzip directory.\n",
        "            None if fail.\n",
        "        \"\"\"\n",
        "        # Check if gsutil is installed\n",
        "        cmd = 'which gsutil'\n",
        "        errmsg = '|E| Please install gsutil from \"{}\"'.format(Gspull.GSUTIL_URL)\n",
        "        gsutil = Gspull._shell(cmd, errmsg).strip()\n",
        "        ret = None\n",
        "        try:\n",
        "            # Run gsutil\n",
        "            cmd = '{} cp {} {}'.format(gsutil, gs_path, filename)\n",
        "            Gspull._shell(cmd)\n",
        "            # Run unzip\n",
        "            rex = re.search(r'((.*)/\\d{8}_\\d{6}.*)_(TEST_.*)_coex.zip', filename)\n",
        "            cmd = '{} {} \\\\*.gz -d {}'.format(\n",
        "                Gspull.UNZIP + (' -t' if test else ''), filename, rex.group(2))\n",
        "            Gspull._shell(cmd)\n",
        "            ret = str(Path(rex.group(1))/rex.group(3))\n",
        "        except:\n",
        "            logging.error('|E| %s\\t%s', gs_path, filename)\n",
        "        # Remove zip file if asked\n",
        "        if ret and not keep and Path(filename).exists():\n",
        "            cmd = '{} {}'.format(Gspull.RM, filename)\n",
        "            Gspull._shell(cmd)\n",
        "        return ret\n",
        "\n",
        "\n",
        "class Plib():\n",
        "    \"\"\"Class definition for bokeh plot.\"\"\"\n",
        "    hv.extension('bokeh')\n",
        "\n",
        "    AX1_REX = re.compile('(Pressure|Orientation|Temperature)')\n",
        "    PLOT_WIDTH = 500\n",
        "    PLOT_HEIGHT = 300\n",
        "    def _new_axes(dfi, yrex, name):\n",
        "        \"\"\"Convert generic y labels to sensor specific.\n",
        "\n",
        "        Args:\n",
        "            yrex: List of (pat, axes) to match.\n",
        "\n",
        "        Returns:\n",
        "            Relabelled dataframe, and y label.\n",
        "        \"\"\"\n",
        "        axes = None\n",
        "        for pat, axes in yrex:\n",
        "            mex = pat.search(name)\n",
        "            if mex:\n",
        "                break\n",
        "        if axes is None:\n",
        "            axes = mex.groups()\n",
        "        dfi = dfi.rename(columns={'c%d' % i: ax for i, ax in enumerate(axes)})\n",
        "        return dfi, axes\n",
        "\n",
        "\n",
        "    def _make_line(name, dfi, cfg):\n",
        "        \"\"\"Make a line plot.\n",
        "\n",
        "        Args:\n",
        "            name: Sensor name (used as title).\n",
        "            dfi: Dataframe to be plotted.\n",
        "            cfg: Plot configuration.\n",
        "\n",
        "        Returns:\n",
        "            Bokeh line plots.\n",
        "        \"\"\"\n",
        "        # Make sure time is sorted\n",
        "        dfi = dfi.sort_values('time')\n",
        "        # Flexible axes and tooltips from pattern searches\n",
        "        dfi, axes = Plib._new_axes(dfi, cfg['yrex'], name)\n",
        "        tooltips = [('time', '@time{0.000}')] + [\n",
        "                    (ax, '@{%s}{0.000}' % ax) for ax in axes]\n",
        "        # Create figures for one sensor type\n",
        "        figs = []\n",
        "        tools = 'xpan,box_zoom,save,reset'\n",
        "        for idx, axi in enumerate(axes):\n",
        "            fig = figure(x_axis_label='Time (sec)', y_axis_label=axi,\n",
        "                        tooltips=tooltips, tools=tools,\n",
        "                        plot_width=Plib.PLOT_WIDTH, plot_height=Plib.PLOT_HEIGHT)\n",
        "            fig.line(x='time', y=axi, source=ColumnDataSource(dfi),\n",
        "                    line_width=2, color=Spectral10[idx])\n",
        "            # No Bokeh link; Shared toolbar at above and controlling xpan\n",
        "            fig.toolbar.logo = None\n",
        "            if idx == 0:\n",
        "                fig.title = name\n",
        "                fig.toolbar_location = 'above'\n",
        "            else:\n",
        "                fig.title = ' '\n",
        "                fig.toolbar_location = None\n",
        "                fig.tools = figs[0].tools\n",
        "                fig.x_range = figs[0].x_range\n",
        "            # Show notes of mean & std\n",
        "            text = 'mean: {:.3f}, std: {:.3f}'.format(\n",
        "                dfi[axi].mean(), dfi[axi].std())\n",
        "            stat = Label(x=10, y=5, x_units='screen', y_units='screen',\n",
        "                text=text, text_font_size='12px',\n",
        "                background_fill_color='white', background_fill_alpha=.7)\n",
        "            fig.add_layout(stat)\n",
        "            # Append figure(s) of one sensor type\n",
        "            figs.append(fig)\n",
        "        return figs\n",
        "\n",
        "\n",
        "    def _make_box(name, dfi, cfg):\n",
        "        \"\"\"Make a box plot.\n",
        "\n",
        "        Args:\n",
        "            name: Sensor name (used as title).\n",
        "            dfi: Dataframe to be plotted.\n",
        "            cfg: Plot configuration.\n",
        "\n",
        "        Returns:\n",
        "            Bokeh line plots.\n",
        "        \"\"\"\n",
        "        # Reset multiindex for Holoviews\n",
        "        dfi.reset_index(dfi.index.names[:-1], inplace=True)\n",
        "        # Flexible axes and tooltips from pattern searches\n",
        "        dfi, axes = Plib._new_axes(dfi, cfg['yrex'], name)\n",
        "        # Create figures for one sensor type\n",
        "        els = []\n",
        "        for idx, axi in enumerate(axes):\n",
        "            box = hv.BoxWhisker(dfi, cfg['xdim'], axi)\n",
        "            hover = HoverTool(tooltips=[cfg['xtip'], (axi, '@{%s}{0.000}' % axi)])\n",
        "            box.opts(title=name if idx == 0 else '.',\n",
        "                    default_tools=['pan', 'box_zoom', 'save', hover, 'reset'],\n",
        "                    width=Plib.PLOT_WIDTH, height=Plib.PLOT_HEIGHT, xrotation=30,\n",
        "                    box_fill_color=Spectral10[idx], fontsize={'xticks': 7},\n",
        "                    ylabel=axi, labelled=[])\n",
        "            els.append(box)\n",
        "\n",
        "        plot = hv.NdLayout({axi: els[i] for axi, i in\n",
        "                        zip(axes, range(len(axes)))}, kdims=name).cols(1)\n",
        "        figs = hv.renderer('bokeh').get_plot(plot).state\n",
        "        figs.children[0].toolbar.logo = None\n",
        "        return figs\n",
        "\n",
        "\n",
        "    def plot_it(ftype, dframe, cfg):\n",
        "        \"\"\"Line/Box plot using Bokeh/Holoviews.\n",
        "\n",
        "        Args:\n",
        "            ftype: Figure type (line/box)\n",
        "            dframe: Dataframe to be plotted.\n",
        "            cfg: Plot configuration.\n",
        "        \"\"\"\n",
        "        # groupby sepecified at outer layer\n",
        "        ## Line: project, build, serial/aggressor, iref\n",
        "        ## Box: project, build, serial, aggressor, iref\n",
        "        for idx, dfr in dframe.groupby(by=cfg['groupby']):\n",
        "            # Sensor data of the same origin into one bundle\n",
        "            bundle = defaultdict(list)\n",
        "            for name in dfr.index.get_level_values(cfg['sensor']).unique():\n",
        "                bundle[name.split()[0]].append(name)\n",
        "            # Plot each bundle in one row\n",
        "            rows = []\n",
        "            for names in bundle.values():\n",
        "                row = []\n",
        "                for name in names:\n",
        "                    if ftype == 'box':\n",
        "                        dfi = dfr.xs(name, level=cfg['sensor']).loc[:, 'time':]\n",
        "                        row.append(Plib._make_box(name, dfi, cfg))\n",
        "                    elif ftype == 'line':\n",
        "                        dfi = dfr.loc[idx + (name,), 'time':]\n",
        "                        row.append(Plib._make_line(name, dfi, cfg))\n",
        "                rows += [row, Spacer(height=60)]\n",
        "            # Add a header\n",
        "            title = '-'.join(idx)\n",
        "            header = Div(text='<h2>{}</h2>'.format(title),\n",
        "                        style={'text-align': 'center'})\n",
        "            doc = column(header, layout(children=rows))\n",
        "            if cfg['figdir'] is None:\n",
        "                show(doc)\n",
        "            else:\n",
        "                outfile = Path(cfg['figdir']).joinpath(\n",
        "                            '{}-{}.html'.format(title, ftype))\n",
        "                logging.info('|I| Output file: %s', outfile)\n",
        "                output_file(outfile, title=title)\n",
        "                save(doc)\n",
        "\n",
        "\n",
        "class Senfi():\n",
        "    \"\"\"Class definition for coex sensor data and plot.\"\"\"\n",
        "    # Set global logging\n",
        "    logging.basicConfig(level=logging.INFO,\n",
        "                        format='%(asctime)s - %(message)s',\n",
        "                        datefmt='%Y-%m-%d %H:%M:%S')\n",
        "    # Global variables\n",
        "    PICKLE_FILE = '/tmp/sensor_dataframe.pickle'\n",
        "    _MG = 1 / 0.0098\n",
        "    _DEG = 180000 / np.pi\n",
        "    _ECG_MV = 1/(2**21)*(1.2/21)*1e3\n",
        "    CODE_DF = pd.DataFrame(\n",
        "        columns=['code', 'multiplier'],\n",
        "        data=[\n",
        "    # Standard ID\n",
        "    # https://android.googlesource.com/platform/frameworks/native/+/refs/heads/master/include/android/sensor.h#76\n",
        "            [ 1,       _MG],        # Accel (Cal)   435 Hz\n",
        "            [ 2,       1],          # Mag (Cal)     100 Hz\n",
        "            [ 3,       1],          # Orientation   109 Hz\n",
        "            [ 4,       _DEG],       # Gyro (Cal)    435 Hz\n",
        "            [ 6,       1],          # Baro          25 Hz\n",
        "    #        [11,       1],         # Rotation\n",
        "            [14,       1],          # Mag (Unc)     100 Hz\n",
        "            [16,       _DEG,],      # Gyro (Unc)\n",
        "    #        [20,       1,],        # GeoMag        100 Hz\n",
        "            [35,       _MG,],       # Accel (Unc)   435 Hz\n",
        "            [37,       1,],         # PPG\n",
        "            [39,       _ECG_MV,],   # ECG\n",
        "    # TODO: Custom sensors maybe product-specific.\n",
        "            [65538,    1],\n",
        "            [65539,    1],\n",
        "            [65540,    1],\n",
        "            [33172002, 1],          # IMU Temp      1.7 Hz\n",
        "            [33172003, 1],          # Baro Temp     25 Hz\n",
        "            [33172004, 1],          # Mag Temp\n",
        "        ]).set_index('code')\n",
        "    # read_csv arguments for different sensors\n",
        "    _CMAX = 3\n",
        "    _COLS = ['code', 'fullname', 'timestamp',\n",
        "            *['c{}'.format(i) for i in range(_CMAX)]]\n",
        "    _TYPE = [('code', np.int32), ('timestamp', np.int64),\n",
        "            *[('c{}'.format(i), np.float64) for i in range(_CMAX)]]\n",
        "    CSV_ARGS = [\n",
        "        ('sensors', dict(usecols=[2, 3, 4, 5, 6, 7], names=_COLS[:6],\n",
        "            dtype=dict(_TYPE[:5]), converters={'fullname': str})),\n",
        "        # PPG: 37.0 TS: 467069638549 Data: 89.000000 76.000000 50.000000\n",
        "        #      -12.000000 3552.000000 3531.000000\n",
        "        ('ppg_data', dict(sep=' ', usecols=[1, 2, 3, 5, 6, 7], names=_COLS[:6],\n",
        "            dtype=dict(_TYPE[:5]), converters={'fullname': lambda x: 'PPG'},\n",
        "            engine='python', skiprows=1, skipfooter=3, index_col=False)),\n",
        "        # ECG: 39.0 TS: 1069311971892 Data: -172.000000\n",
        "        ('ecg_data', dict(sep=' ', usecols=[1, 2, 3, 5], names=_COLS[:4],\n",
        "            dtype=dict(_TYPE[0:3]), converters={'fullname': lambda x: 'ECG'},\n",
        "            engine='python', skiprows=1, skipfooter=3, index_col=False)),\n",
        "    ]\n",
        "    # Dataframe column names based on sensor types\n",
        "    REAL_COLS = [\n",
        "        (re.compile(r'(Pressure|Orientation|Temperature)'), None),\n",
        "        (re.compile(r'(PPG)'), ('PD12_Green', 'PD3_Red', 'PD3_IR')),\n",
        "    #                            'PD3_IR_prox', 'PD12_ambient', 'PD3_ambient')),\n",
        "        (re.compile(r'(ECG)'), ('ADC',)),\n",
        "        (re.compile(r'(.*)'), ('x', 'y', 'z')),\n",
        "    ]\n",
        "\n",
        "    def __init__(self, args):\n",
        "        \"\"\"Init routine to store args, and prepare output directory.\n",
        "\n",
        "        Args:\n",
        "            args: User arguments.\n",
        "        \"\"\"\n",
        "        self.args = args\n",
        "        # Create outdir if not already.\n",
        "        args.outdir = Path(args.outdir).expanduser().resolve() / 'senfi'\n",
        "        args.outdir.mkdir(parents=True, exist_ok=True)\n",
        "        # Create figures directory\n",
        "        figdir = None\n",
        "        if args.outform:\n",
        "            figdir = args.outdir / 'figures'\n",
        "            figdir.mkdir(parents=True, exist_ok=True)\n",
        "        self.plot_cfg = {\n",
        "            'figdir': figdir,\n",
        "            'sensor': 'fullname',\n",
        "            'yrex': self.REAL_COLS,\n",
        "        }\n",
        "\n",
        "    def read_csv(self, infile):\n",
        "        \"\"\"Read all csv files in .gz format in subdirectory.\n",
        "\n",
        "        Args:\n",
        "            infile: .gz file or directory containing .gz files.\n",
        "                    This must conform to EECoexer generated log path.\n",
        "\n",
        "        Returns:\n",
        "            MultiIndex dataframe containing all sensor data under infile.\n",
        "        \"\"\"\n",
        "        def _read_frames(paths):\n",
        "            # CSV file format: code, fullname, timestamp, data...\n",
        "            frames = []\n",
        "            for pat, args in self.CSV_ARGS:\n",
        "                args = args.copy()\n",
        "                names = args['names']\n",
        "                # Workaround: usecols falsely assumes NaN if first row has missing column\n",
        "                if pat == 'sensors':\n",
        "                    skipcols = list(range(2))\n",
        "                    args['names'] = ['_{}'.format(i) for i in skipcols] + names\n",
        "                    args['usecols'] = skipcols + args['usecols']\n",
        "                for path in filter(lambda x: pat in str(x), paths):\n",
        "                    try:\n",
        "                        frames.append(pd.read_csv(path, **args)[names])\n",
        "                    except EOFError as exc:\n",
        "                        logging.error('|E| Failed to read %s -> %s', path, exc)\n",
        "                    except ValueError as exc:\n",
        "                        logging.error('|E| Incorrect CSV format %s -> %s', path, exc)\n",
        "            return frames\n",
        "\n",
        "        # infile may be a file or directory\n",
        "        inf = Path(infile).expanduser().resolve()\n",
        "        paths = [inf]\n",
        "        if inf.is_dir() :\n",
        "            paths = list(inf.rglob('*.gz'))\n",
        "        # Read csv, and concat all dataframes\n",
        "        ## MultiIndex extracted from path\n",
        "        idx_names = ['project', 'serial', 'build', 'aggressor', 'iref', 'fullname']\n",
        "        frames = _read_frames(paths)\n",
        "        rex = re.compile(r'\\d{8}_\\d{6}_(.+)_(.+)_(.+)/TEST_[a-zA-Z]+(.*)/(.*?(?:sensors|data))')\n",
        "        keys = [rex.search(str(path)).groups() for path in paths]\n",
        "        if not self.args.band:\n",
        "            fun = lambda x: x if x[-1].startswith('Idle') else (\n",
        "                            x[:-1] + ('sensors',) if 'sensors' in x[-1] else (\n",
        "                            x[:-1] + ('ppg_data',) if 'ppg_data' in x[-1] else (\n",
        "                            x[:-1] + ('ecg_data',))))\n",
        "            keys = map(fun, keys)\n",
        "        dfr = pd.concat(frames, keys=keys, names=idx_names[:-1])\n",
        "        dfr = dfr.swaplevel('serial', 'build')\n",
        "        # Add 'fullname' to MultiIndex\n",
        "        dfr = dfr.set_index('fullname', append=True).swaplevel()\n",
        "        dfr.sort_index(inplace=True)\n",
        "        # Add time column in sec\n",
        "        ## groupby (project, build, serial, aggressor, iref, fullname)\n",
        "        for idx, dfi in dfr.groupby(by=dfr.index.names[:-1]):\n",
        "            tmin = dfi['timestamp'].min()\n",
        "            dfr.loc[idx, 'timestamp'] = (dfi['timestamp'] - tmin) / 10**9\n",
        "        # index: project, build, serial, aggressor, iref, fullname, None\n",
        "        # column: code, time, ...\n",
        "        return dfr.rename(columns={'timestamp': 'time'})\n",
        "\n",
        "    def _get_dirlist(self):\n",
        "        \"\"\"Prepare directory list dataframe with column (gs_path, filename).\n",
        "            gs_path is empty for local directories.\n",
        "\n",
        "        Returns:\n",
        "            Dataframe of (gs_path, filename)\n",
        "        \"\"\"\n",
        "        args = self.args\n",
        "        inf = Path(args.infile).expanduser().resolve()\n",
        "        if inf.suffix in ('.xlsx', '.csv'):\n",
        "            # Read xlsx/csv input file of column (gs_path, filename).\n",
        "            dfr = Gspull.gs_dataframe(args)\n",
        "        else:\n",
        "            # Find all .gz files under infile directory.\n",
        "            paths = filter(lambda x: x.suffix == '.gz', inf.rglob('*'))\n",
        "            dfr = pd.DataFrame({\n",
        "                    'gs_path': '',\n",
        "                    'filename': [str(path.parent) for path in paths]})\n",
        "            self._select_data(dfr, False)\n",
        "        dfr.drop_duplicates(inplace=True)\n",
        "        return dfr\n",
        "\n",
        "    def _select_data(self, dfr, index=True):\n",
        "        \"\"\"Select data to process/plot based on user arguments.\n",
        "\n",
        "        Args:\n",
        "            dfr: Dataframe to be filtered.\n",
        "            index: True/False to search in index/column\n",
        "\n",
        "        Returns:\n",
        "            Dataframe after filtering.\n",
        "        \"\"\"\n",
        "        args = self.args\n",
        "        if index:\n",
        "            contains = dfr.index.get_level_values('aggressor').str.contains\n",
        "        else:\n",
        "            contains = dfr['filename'].str.contains\n",
        "        # -x/-y to exclude/include aggressor/serial\n",
        "        mask = False\n",
        "        if args.exclude:\n",
        "            mask |=  contains('|'.join(args.exclude.split(',')))\n",
        "        if args.include:\n",
        "            mask |= ~contains('|'.join(args.include.split(',')))\n",
        "        # -s to select sensor type\n",
        "        if index and args.sensor:\n",
        "            contains = dfr.index.get_level_values('fullname').str.contains\n",
        "            mask |= ~contains('|'.join(args.sensor.split(',')))\n",
        "        if not isinstance(mask, bool):\n",
        "            dfr.drop(dfr[mask].index, inplace=True)\n",
        "        return dfr\n",
        "\n",
        "    def _process_data(self, dfr):\n",
        "        \"\"\"Process data - raw, calibrated, or idle mean.\n",
        "\n",
        "        Args:\n",
        "            dfr: Dataframe to be processed.\n",
        "\n",
        "        Returns:\n",
        "            Dataframe after data processing.\n",
        "        \"\"\"\n",
        "        args = self.args\n",
        "        # Column names after (code, time, ...)\n",
        "        cols = dfr.columns.tolist()[2:]\n",
        "        # -w to use raw data\n",
        "        if not args.raw:\n",
        "            dfr = dfr.join(self.CODE_DF, on='code')\n",
        "            dfr = dfr.assign(**{c: dfr[c] * dfr['multiplier'] for c in cols})\n",
        "            newbie = dfr[dfr['multiplier'].isna()].index.get_level_values('fullname')\n",
        "            if newbie.any():\n",
        "                logging.debug('Unknown types: %s', newbie.unique())\n",
        "            dfr.dropna(inplace=True, subset=['multiplier'])\n",
        "            dfr.drop(columns='multiplier', inplace=True)\n",
        "        # -c to use calibrated data\n",
        "        names = dfr.index.get_level_values('fullname').unique()\n",
        "        for name in filter(lambda x: x.endswith('-Uncalibrated'), names):\n",
        "            if not args.calibrated:\n",
        "                name = name.split('-')[0]\n",
        "            if name in names:\n",
        "                dfr.drop(index=name, level='fullname', inplace=True)\n",
        "        # -m to substract idle mean\n",
        "        if args.imean:\n",
        "            names = ['project', 'build', 'serial', 'aggressor', 'fullname']\n",
        "            for idx, dfi in dfr.groupby(by=names):\n",
        "                if (dfi.index.get_level_values(\n",
        "                    'iref').str.contains('Idle_Reference_sensors').any()):\n",
        "                    idx1 = idx[0:-1] + ('Idle_Reference_sensors', idx[-1])\n",
        "                    dfr.loc[dfi.index, cols] -= dfi.loc[idx1, cols].mean()\n",
        "        return dfr\n",
        "\n",
        "    def _write_csv(self, dfr):\n",
        "        \"\"\"Write .csv files groupby sensor types.\n",
        "\n",
        "        Args:\n",
        "            dfr: Dataframe to be written.\n",
        "        \"\"\"\n",
        "        figdir = self.plot_cfg['figdir']\n",
        "        for idx, dfi in dfr.groupby(by=dfr.index.names[:-1]):\n",
        "            filename = figdir.joinpath('{}.csv'.format('-'.join(idx)))\n",
        "            logging.debug('Writing csv files: %s', filename)\n",
        "            dfi.loc[:,'time':].to_csv(filename, index=False)\n",
        "\n",
        "    def _worker(self, gs_path, filename):\n",
        "        \"\"\"Mutiprocessing workers to process each device/aggressor in parallel.\n",
        "\n",
        "        Args:\n",
        "            gs_path: GCS bucket id. None a for local file.\n",
        "            filename: directory or zip file name containing .gz sensor data.\n",
        "\n",
        "        Returns:\n",
        "            MultiIndex dataframe containing all sensor data.\n",
        "        \"\"\"\n",
        "        # Read log files as csv into dataframe.\n",
        "        logging.info('|I| Processing %s', filename)\n",
        "        # Pull .zip file from GCS if gs_path specified.\n",
        "        if gs_path:\n",
        "            filename = Gspull.gs_worker(gs_path, filename)\n",
        "            if filename is None:\n",
        "                return pd.DataFrame()\n",
        "        try:\n",
        "            dfr = self.read_csv(filename)\n",
        "        except ValueError:\n",
        "            return pd.DataFrame()\n",
        "        # Process data based on input arguments.\n",
        "        dfr = self._process_data(dfr)\n",
        "        # Plot line if asked (done by worker in parallel).\n",
        "        if self.args.figure == 'line':\n",
        "            self.plot_cfg['groupby'] = dfr.index.names[:5]\n",
        "            Plib.plot_it('line', dfr, self.plot_cfg)\n",
        "        return dfr\n",
        "\n",
        "    def pardo(self):\n",
        "        \"\"\"Spawn multiprocessing workers for each device/aggressor.\n",
        "\n",
        "        Returns:\n",
        "            MultiIndex dataframe containing all sensor data.\n",
        "        \"\"\"\n",
        "        args = self.args\n",
        "        # Try to load pickle if no input file specified.\n",
        "        if args.infile is None and Path(self.PICKLE_FILE).exists():\n",
        "            logging.info('Read dataframe from %s', self.PICKLE_FILE)\n",
        "            with open(self.PICKLE_FILE, 'rb') as fid:\n",
        "                dfr = pickle.load(fid)\n",
        "            dfr = self._select_data(dfr)\n",
        "            # Run in single process, not as efficient.\n",
        "            if args.figure == 'line':\n",
        "                self.plot_cfg['groupby'] = dfr.index.names[:5]\n",
        "                Plib.plot_it('line', dfr, self.plot_cfg)\n",
        "        else:\n",
        "            # Get directories with qualified .gz files.\n",
        "            ## Retrieve from GCS if an xlsx/csv file is specified.\n",
        "            dir_df = self._get_dirlist()\n",
        "            # Multiprocessing pool workers\n",
        "            with mp.Pool(min(mp.cpu_count(), len(dir_df))) as mpl:\n",
        "                frames = mpl.starmap(self._worker, dir_df.values.tolist())\n",
        "            dfr = pd.concat(frames)\n",
        "            # Pickle it to save time during development\n",
        "            if args.pickle:\n",
        "                with open(self.PICKLE_FILE, 'wb') as fid:\n",
        "                    pickle.dump(dfr, fid, pickle.HIGHEST_PROTOCOL)\n",
        "        if args.outform == 'csv':\n",
        "            self._write_csv(dfr)\n",
        "        # Boxplot if asked.\n",
        "        if args.figure == 'box':\n",
        "            xdim = ['serial', 'aggressor']\n",
        "            xtip = ('Aggressor', 'SENSOR@aggressor')\n",
        "            if args.agg_ax:\n",
        "                xdim = ['aggressor', 'serial']\n",
        "                xtip = ('Serial', '@serial')\n",
        "            self.plot_cfg.update({\n",
        "                'xdim': xdim,\n",
        "                'xtip': xtip,\n",
        "                'groupby': ['project', 'build', xdim[0], 'iref'],\n",
        "            })\n",
        "            Plib.plot_it('box', dfr, self.plot_cfg)\n",
        "        return dfr\n",
        "\n",
        "    @staticmethod\n",
        "    def filter_data():\n",
        "        \"\"\"filter senfi dataframe.\"\"\"\n",
        "        try:\n",
        "            serials_filter = dropdown_data_senfi_serials.filter_df_by_selected_data(senfi_df.serial)\n",
        "        except NameError:\n",
        "            serials_filter = None\n",
        "\n",
        "        try:\n",
        "            testcases_filter = dropdown_data_senfi_testcases.filter_df_by_selected_data(senfi_df.test_case)\n",
        "        except NameError:\n",
        "            testcases_filter = None\n",
        "\n",
        "        senfi_filter = senfi_df.station.str.contains('C_C10_1_WiredCharging|C_C10_4_Sensor')\n",
        "\n",
        "        if serials_filter is not None:\n",
        "            senfi_filter = senfi_filter & serials_filter\n",
        "        \n",
        "        if testcases_filter is not None:\n",
        "            senfi_filter = senfi_filter & testcases_filter\n",
        "        \n",
        "        senfi_filter = senfi_df[senfi_filter]\n",
        "        senfi_filter = senfi_filter[['gs_path', 'filename']].drop_duplicates()\n",
        "\n",
        "        # Ensure senfi filter not contain all the devices\n",
        "        if serials_filter is None and testcases_filter is None:\n",
        "            senfi_filter = pd.DataFrame()\n",
        "        \n",
        "        senfi_filter.to_csv('senfi.csv', index=False)\n",
        "\n",
        "        # Cleanup tmp folder before senfi plot it\n",
        "        !rm -rf /tmp/senfi\n",
        "\n",
        "    @staticmethod\n",
        "    def download_data():\n",
        "        if Path('/tmp/senfi/figures').exists:\n",
        "            senfi_filename = '/tmp/senfi.zip'\n",
        "\n",
        "            !rm -f '/tmp/senfi.zip' >/dev/null 2>&1\n",
        "            !zip -rjq /tmp/senfi.zip /tmp/senfi/figures >/dev/null 2>&1\n",
        "            !sleep 3\n",
        "\n",
        "            try:\n",
        "                files.download(senfi_filename)\n",
        "            except FileNotFoundError:\n",
        "                senfi_filename = None\n",
        "\n",
        "    @staticmethod\n",
        "    def main():\n",
        "        \"\"\"Argument parsing.\"\"\"\n",
        "        parser = argparse.ArgumentParser(\n",
        "            description='Plot sensor data generated by EECoexer',\n",
        "            formatter_class=argparse.RawDescriptionHelpFormatter,)\n",
        "        parser.add_argument('-i', '--infile', default=None,\n",
        "            help='This specifies the input directory/file. '\n",
        "                'INFILE could be a directory or an .xlsx/.csv file. '\n",
        "                'For a directory, senfi would search for all .gz files '\n",
        "                'under the subdirectory assuming they are sensor data files '\n",
        "                'generated by EECoxer. For an .xlsx/.csv file, it must contain '\n",
        "                'a worksheet with two columns gs_paths and filename, '\n",
        "                'where gs_path is the GCS bucket id and filename is the name of '\n",
        "                'the zip file created by OLOG.')\n",
        "        parser.add_argument('-s', '--sheet', default=0, type=int,\n",
        "            help='Valid only if INFILE is an .xlsx file. It could be a number '\n",
        "                '(0, 1, ...) or a sheet name (DVT1.0, EVT1.0, ...).')\n",
        "        parser.add_argument('-w', '--raw', action='store_true',\n",
        "            help='Use raw data without unit conversion. This applies only to '\n",
        "                'accelerometer (converting to milli-gravity) and gyroscope '\n",
        "                '(converting to milli-degree/second).')\n",
        "        parser.add_argument('-c', '--calibrated', action='store_true',\n",
        "            help='Use calibrated data, default is to use uncalibrated data.')\n",
        "        parser.add_argument('-m', '--imean', action='store_true',\n",
        "            help='Subtract idle reference mean from each sensor data. '\n",
        "                'This does not apply to temperature and orientation sensor.')\n",
        "        parser.add_argument('-l', '--limit', default=0, type=int,\n",
        "            help='Limit the number of buckets to pull from GCS. '\n",
        "                'This is a convenience option during development, '\n",
        "                'since an .xlsx file may contain thousands of buckets, '\n",
        "                'which would jam your local drive.')\n",
        "        parser.add_argument('-x', '--exclude', default=None,\n",
        "            help='Exclude those with matching pattern.')\n",
        "        parser.add_argument('-y', '--include', default=None,\n",
        "            help='Include those with matching pattern.')\n",
        "        parser.add_argument('-r', '--sensor', default=None,\n",
        "            help='Include sensor types. EXLUDE/INCLUDE/SENSOR are regular '\n",
        "                'expressions to exclude/include aggressor types, and/or '\n",
        "                'include sensor types. These are convenient if you just '\n",
        "                'want to plot a subset of aggressors and/or sensors.')\n",
        "        parser.add_argument('-b', '--band', action='store_true',\n",
        "            help='Separate RF/WiFi bands/channels if so configured.')\n",
        "        parser.add_argument('-f', '--figure', default=None,\n",
        "            help='Figure type, currently only line plot and box plot are '\n",
        "                'supported.')\n",
        "        parser.add_argument('-a', '--agg_ax', action='store_true',\n",
        "            help='For box plot only. If specified, the box plot would use '\n",
        "                '(aggressor, serial) as the x-axis, instead of the usual '\n",
        "                '(serial, aggressor).')\n",
        "        parser.add_argument('-o', '--outdir', default='/tmp',\n",
        "            help='Output directory')\n",
        "        parser.add_argument('-t', '--outform', default=None,\n",
        "            help='Output format, currently only html and csv are supported.')\n",
        "        parser.add_argument('-p', '--pickle', action='store_true',\n",
        "            help='For development only. Run Python pickle to save dataframe '\n",
        "                'for next run.')\n",
        "        # Parse arguments and run multiprocessing on each device/aggressor\n",
        "        args = parser.parse_args(['--infile', '/content/senfi.csv',\n",
        "                                  '--figure', Figure_Type,\n",
        "                                  '--outform', Outform_Type])\n",
        "        Senfi(args).pardo()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omZ-IavZVMeu"
      },
      "source": [
        "##Sensor Post Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofzwFmPuVSON"
      },
      "source": [
        "#@title Filter {vertical-output: true, display-mode: 'form'}\n",
        "\n",
        "sensor_df = QueryStation.sensor_station()\n",
        "dropdown_data_serials = DropdownMenu('Serial', sensor_df.serial.unique())\n",
        "#dropdown_data_serials.show_readme()\n",
        "dropdown_data_serials.render_multiple_dropdown()\n",
        "dropdown_data_serials.register_callback()\n",
        "\n",
        "dropdown_data_configs = DropdownMenu('Config', sensor_df.device_config.unique())\n",
        "#dropdown_data_configs.show_readme()\n",
        "dropdown_data_configs.render_multiple_dropdown()\n",
        "dropdown_data_configs.register_callback()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wDmU5CdVYVS"
      },
      "source": [
        "#@title Plots\n",
        "    \n",
        "SensorPlotly.process(sensor_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qXDyAMhc6ZA"
      },
      "source": [
        "#@title Data table\n",
        "\n",
        "fail_summay = True #@param {type:'boolean'}\n",
        "Summary.check_fail_summary(sensor_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "YbXOS5v0VhKg"
      },
      "source": [
        "#@title Barometer Diff table\n",
        "\n",
        "# try:\n",
        "#   from colabtools.interactive_table import Create as DataTable\n",
        "# except:\n",
        "#   from google.colab.data_table import DataTable\n",
        "\n",
        "# PrintSummary(pressure_diff_df)\n",
        "# df = pressure_diff_df.drop(columns=['log_date','log_time', 'measurement_date_china', 'measurement_time_china'])\n",
        "# DataTable(df, max_columns=30, max_rows=60000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MF_28kouzUZ"
      },
      "source": [
        "##BTS Post Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIJWjzfXu8BT"
      },
      "source": [
        "#@title Filter {vertical-output: true, display-mode: 'form'}\n",
        "\n",
        "sensor_df = QueryStation.sensor_station()\n",
        "dropdown_data_serials = DropdownMenu('Serial', sensor_df.serial.unique())\n",
        "#dropdown_data_serials.show_readme()\n",
        "dropdown_data_serials.render_multiple_dropdown()\n",
        "dropdown_data_serials.register_callback()\n",
        "\n",
        "dropdown_data_configs = DropdownMenu('Config', sensor_df.device_config.unique())\n",
        "#dropdown_data_configs.show_readme()\n",
        "dropdown_data_configs.render_multiple_dropdown()\n",
        "dropdown_data_configs.register_callback()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBSoR29gu_Ft"
      },
      "source": [
        "#@title Plots\n",
        "    \n",
        "SensorPlotly.process(sensor_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CzBBoQzvIYG"
      },
      "source": [
        "#@title Data table\n",
        "\n",
        "fail_summay = True #@param {type:'boolean'}\n",
        "Summary.check_fail_summary(sensor_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyqxugDJE9vK"
      },
      "source": [
        "##Camera NFC Post Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fvc9SBunE30A",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Plots\n",
        "\n",
        "nfc_df = QueryStation.nfc_station()\n",
        "device_configs = Base.GetDeviceConfigList(nfc_df['merged_df'])\n",
        "nfc_plotly = NFCPlotly(spec=0, zmin=0, zmax=1, title='Camera NFC',\n",
        "                       multiaxes=False, device_configs=device_configs,\n",
        "                       hover_x_title='Value', marginal=None)\n",
        "nfc_plotly.plots()\n",
        "\n",
        "camera_plotly = CameraDarkFramePlotly(spec=10, zmin=-1, zmax=15,\n",
        "                                        title='CAM For 190, 191 Dark NFC',\n",
        "                                        device_configs=device_configs,\n",
        "                                        multiaxes=True, marginal=None)\n",
        "camera_plotly.Show(nfc_df['merged_df'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nwig_SibKdr5",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Data table\n",
        "\n",
        "fail_summay = False #@param {type: 'boolean'}\n",
        "Summary.check_fail_summary(nfc_df['nfc_data_table'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-KVIxJbVlHY"
      },
      "source": [
        "##Camera Dark Frame Post Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpC4lR8dVlwM"
      },
      "source": [
        "#@title Filter {vertical-output: true, display-mode: 'form'}\n",
        "\n",
        "# This field is to select specific device serials to plot data\n",
        "# If there is selected serial, then it will plot data of selected serials.\n",
        "# Otherwise, it will plot all data in the next cell.\n",
        "\n",
        "cam_df = QueryStation.camera_station()\n",
        "dropdown_data_cams = {}\n",
        "for _, cam_data in cam_df.items():\n",
        "    if not cam_data['df'].empty:\n",
        "        cam = 'CAM' + cam_data['id']\n",
        "        cam_menu = DropdownMenu(cam, cam_data['df'].serial.unique())\n",
        "        cam_menu.render_multiple_dropdown()\n",
        "        cam_menu.request_cam_data.setdefault(cam, [])\n",
        "        cam_menu.register_cam_callback()\n",
        "        dropdown_data_cams[cam] = cam_menu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXmfoo7fVt9w"
      },
      "source": [
        "#@title Plots\n",
        "\n",
        "for group_name, cam_data in cam_df.items():\n",
        "    if not cam_data['df'].empty:\n",
        "        victim ='CAM' + cam_data['id']\n",
        "        title=f'{victim} Dark Frame'\n",
        "\n",
        "        try: \n",
        "            serials_filter = dropdown_data_cams[victim].filter_df_by_selected_cam_data(cam_data['df'], victim)\n",
        "        except NameError:\n",
        "            serials_filter = None\n",
        "\n",
        "        if serials_filter is not None:\n",
        "            cam_data['df'] = cam_data['df'][serials_filter]\n",
        "        device_configs = Base.GetDeviceConfigList(cam_data['df'])\n",
        "        camera_plotly = CameraDarkFramePlotly(spec=10, zmin=-1,\n",
        "                                              zmax=15, title=title,\n",
        "                                              device_configs=device_configs,\n",
        "                                              multiaxes=True, marginal=None)\n",
        "        camera_plotly.Show(cam_data['df'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFu9mttHVpYw"
      },
      "source": [
        "#@title Data table\n",
        "\n",
        "fail_summay = True #@param {type: 'boolean'}\n",
        "\n",
        "camera_df = None\n",
        "for cam_data in cam_df.values():\n",
        "    if camera_df is None:\n",
        "        camera_df = cam_data['df']\n",
        "    else:\n",
        "        camera_df = camera_df.append(cam_data['df'])\n",
        "camera_df.sort_values(by=['test_item', 'serial'], ascending=False, inplace=True)\n",
        "Summary.check_fail_summary(camera_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNGK4D1eWdMx"
      },
      "source": [
        "## Wired Charging Post Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jna2kQTcWZ-J"
      },
      "source": [
        "#@title Plots\n",
        "\n",
        "wc_df = QueryStation.wired_charging_station()\n",
        "SensorPlotly.process(wc_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwGceuCSWjXK"
      },
      "source": [
        "#@title Data table\n",
        "\n",
        "fail_summay = False #@param {type: 'boolean'}\n",
        "Summary.check_fail_summary(wc_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Offsite plot"
      ],
      "metadata": {
        "id": "yoMfog7heJF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Query Database\n",
        "\n",
        "def CreateMissingDataframe(test_df, logs_df, test_item_key=None, key_mask=''):\n",
        "  merged_df=logs_df.merge(test_df, how='left')\n",
        "  serials_list = GetSerialsList(logs_df)\n",
        "  test_cases_list = GetTestCasesList(test_df)\n",
        "  sensors_list = GetSensorsList(test_df)\n",
        "  test_items_list = GetTestItemsList(test_df)\n",
        "\n",
        "  missing_df = FindMissingRaws(merged_df, serials_list, test_cases_list, test_items_list=test_items_list, sensors_list=sensors_list)\n",
        "  missing_df = FillMissingLogs(missing_df, logs_df)\n",
        "  missing_df = FillColumnsOfMissingDataframe(missing_df, logs_df, test_cases_list, test_items_list, test_item_key=test_item_key, key_mask=key_mask)\n",
        "\n",
        "  return missing_df\n",
        "\n",
        "\n",
        "test_case_pattern='^([A-Za-z0-9]+)_'\n",
        "test_item_pattern='^[A-Za-z0-9]+_(.+)$'\n",
        "station_pattern='C_R4_1_WiredCharging' #@param {type:'string'}\n",
        "\n",
        "@dataclasses.dataclass\n",
        "class WiredChargingPlotly:\n",
        "  spec: float\n",
        "  zmax: float\n",
        "  title: str\n",
        "  multiaxes: bool\n",
        "  zmin: float\n",
        "  height: int\n",
        "  width: int\n",
        "  axis_settings: dict\n",
        "\n",
        "  def _BuildHeapmap(self, df_x, df_y, df_z, df_hover):\n",
        "    return Heatmap(\n",
        "        z=df_z,\n",
        "        x=df_x,\n",
        "        y=df_y,\n",
        "        xgap=2,\n",
        "        ygap=2,\n",
        "        zmin = self.zmin,\n",
        "        zmax = self.zmax,\n",
        "        hoverinfo='x+y+z+text',\n",
        "        text=df_hover,\n",
        "    )\n",
        "\n",
        "  def _BuildTraceFigure(self, df):\n",
        "    df_hover = df[['result', 'message']].apply(lambda x: 'Result: {}<br>Message: {}'.format(x[0], x[1]), axis=1)\n",
        "    data = [self._BuildHeapmap(df.serial, df.test_item, df.value, df_hover)]\n",
        "    \n",
        "    layout = Layout(\n",
        "        title=self.title,\n",
        "        xaxis = self.axis_settings,\n",
        "        yaxis = self.axis_settings,\n",
        "        height=self.height,\n",
        "        width=self.width,\n",
        "    )\n",
        "    return Figure(data=data, layout=layout)\n",
        "\n",
        "  def Show(self, df):\n",
        "    fig = self._BuildTraceFigure(df)\n",
        "    fig.show()\n",
        "\n",
        "wc_test_df = QueryData(Table.FACTORY, Project, BUILD_PHASE[Build], station_pattern, test_case_pattern=test_case_pattern, \n",
        "                                         test_item_pattern=test_item_pattern)\n",
        "\n",
        "wc_logs_df = QueryData(Table.LOGS, Project, BUILD_PHASE[Build], station_pattern)\n",
        "\n",
        "# get latest one\n",
        "wc_bench_test_df = wc_test_df[wc_test_df.test_item.notna() & wc_test_df.test_item.str.contains('bench')].copy()\n",
        "wc_bench_test_df = wc_bench_test_df.sort_values(by=['test_date_time'], ascending=False)\n",
        "wc_bench_test_df = wc_bench_test_df.drop_duplicates(['serial', 'test_case', 'test_item'])\n",
        "wc_bench_test_df.drop(columns='test_date_time', inplace=True)\n",
        "\n",
        "wc_logs_df = wc_logs_df.sort_values(by=['test_date_time'], ascending=False)\n",
        "wc_logs_df = wc_logs_df.drop_duplicates(['serial', 'test_case'])\n",
        "\n",
        "victim='RAM105'\n",
        "aggressor='n[0-9]+'\n",
        "wc_ram_fr1_df = ProcessUfsRamDataframe(wc_bench_test_df, wc_logs_df, victim, aggressor)\n",
        "\n",
        "victim='RAM106'\n",
        "aggressor='n[0-9]+'\n",
        "wc_ram_fr2_df = ProcessUfsRamDataframe(wc_bench_test_df, wc_logs_df, victim, aggressor)\n",
        "\n",
        "victim='RAM'\n",
        "aggressor='GSM'\n",
        "wc_ram_gsm_df = ProcessUfsRamDataframe(wc_bench_test_df, wc_logs_df, victim, aggressor)\n",
        "\n",
        "aggressor='802_11'\n",
        "wc_ram_wifi_df = ProcessUfsRamDataframe(wc_bench_test_df, wc_logs_df, victim, aggressor)\n",
        "\n",
        "aggressor='UMTS'\n",
        "wc_ram_umts_df = ProcessUfsRamDataframe(wc_bench_test_df, wc_logs_df, victim, aggressor)\n",
        "\n",
        "aggressor='LTE'\n",
        "wc_ram_lte_df = ProcessUfsRamDataframe(wc_bench_test_df, wc_logs_df, victim, aggressor)\n",
        "\n",
        "misc_aggerssors=['CPU', 'GPU', 'media', 'idle']\n",
        "wc_ram_misc_df = pandas.DataFrame(columns=wc_ram_gsm_df.columns)\n",
        "for aggressor in misc_aggerssors:\n",
        "  wc_ram_misc_df = wc_ram_misc_df.append(ProcessUfsRamDataframe(wc_bench_test_df, wc_logs_df, victim, aggressor))\n",
        "\n",
        "\n",
        "victim='UFS105'\n",
        "aggressor='n[0-9]+'\n",
        "wc_ufs_fr1_df = ProcessUfsRamDataframe(wc_bench_test_df, wc_logs_df, victim, aggressor)\n",
        "\n",
        "victim='UFS106'\n",
        "aggressor='n[0-9]+'\n",
        "wc_ufs_fr2_df = ProcessUfsRamDataframe(wc_bench_test_df, wc_logs_df, victim, aggressor)\n",
        "\n",
        "victim='UFS'\n",
        "aggressor='GSM'\n",
        "wc_ufs_gsm_df = ProcessUfsRamDataframe(wc_bench_test_df, wc_logs_df, victim, aggressor)\n",
        "\n",
        "aggressor='802_11'\n",
        "wc_ufs_wifi_df = ProcessUfsRamDataframe(wc_bench_test_df, wc_logs_df, victim, aggressor)\n",
        "\n",
        "aggressor='UMTS'\n",
        "wc_ufs_umts_df = ProcessUfsRamDataframe(wc_bench_test_df, wc_logs_df, victim, aggressor)\n",
        "\n",
        "aggressor='LTE'\n",
        "wc_ufs_lte_df = ProcessUfsRamDataframe(wc_bench_test_df, wc_logs_df, victim, aggressor)\n",
        "\n",
        "misc_aggerssors=['CPU', 'GPU', 'media', 'idle']\n",
        "wc_ufs_misc_df = pandas.DataFrame(columns=wc_ram_gsm_df.columns)\n",
        "for aggressor in misc_aggerssors:\n",
        "  wc_ufs_misc_df = wc_ufs_misc_df.append(ProcessUfsRamDataframe(wc_bench_test_df, wc_logs_df, victim, aggressor))\n",
        "\n",
        "wc_df = wc_ram_gsm_df.append(wc_ram_fr1_df).append(wc_ram_fr2_df).append(wc_ram_wifi_df).append(wc_ram_umts_df).append(wc_ram_lte_df).append(wc_ram_misc_df)\n",
        "wc_df = wc_df.append(wc_ufs_gsm_df).append(wc_ufs_fr1_df).append(wc_ufs_fr2_df).append(wc_ufs_wifi_df).append(wc_ufs_umts_df).append(wc_ufs_lte_df).append(wc_ufs_misc_df)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "dJTAdnwfeO6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title RAM Plots\n",
        "try:\n",
        "  %create_tabs  GSM, FR1, FR2, WiFi, UMTS, LTE, CPU GPU Media Idle\n",
        "  %switch_to_tab GSM\n",
        "except:\n",
        "  pass\n",
        "victim='RAM'\n",
        "aggressor='GSM'\n",
        "spec=1000\n",
        "zmin=0\n",
        "zmax=3000\n",
        "title=f'Wired Charging {victim} ({aggressor})'\n",
        "height=600\n",
        "width=1600\n",
        "multiaxes=True\n",
        "\n",
        "wc_plotly = WiredChargingPlotly(spec=spec, zmin=zmin, zmax=zmax, \n",
        "                                title=title, multiaxes=multiaxes,\n",
        "                                height=height, width=width, axis_settings=DEFAULT_AXIS_SETTINGS)\n",
        "wc_plotly.Show(wc_ram_gsm_df)\n",
        "\n",
        "try:\n",
        "  %switch_to_tab FR1\n",
        "except:\n",
        "  pass\n",
        "victim='RAM'\n",
        "aggressor='FR1'\n",
        "spec=1000\n",
        "zmin=0\n",
        "zmax=3000\n",
        "title=f'Wired Charging {victim} ({aggressor})'\n",
        "height=400\n",
        "width=1600\n",
        "multiaxes=True\n",
        "\n",
        "wc_plotly = WiredChargingPlotly(spec=spec, zmin=zmin, zmax=zmax, \n",
        "                                      title=title, multiaxes=multiaxes,\n",
        "                                      height=height, width=width, axis_settings=DEFAULT_AXIS_SETTINGS)\n",
        "wc_plotly.Show(wc_ram_fr1_df)\n",
        "\n",
        "try:\n",
        "  %switch_to_tab FR2\n",
        "except:\n",
        "  pass\n",
        "victim='RAM'\n",
        "aggressor='FR2'\n",
        "spec=1000\n",
        "zmin=0\n",
        "zmax=3000\n",
        "title=f'Wired Charging {victim} ({aggressor})'\n",
        "height=400\n",
        "width=1600\n",
        "multiaxes=True\n",
        "\n",
        "wc_plotly = WiredChargingPlotly(spec=spec, zmin=zmin, zmax=zmax, \n",
        "                                      title=title, multiaxes=multiaxes,\n",
        "                                      height=height, width=width, axis_settings=DEFAULT_AXIS_SETTINGS)\n",
        "wc_plotly.Show(wc_ram_fr2_df)\n",
        "\n",
        "try:\n",
        "  %switch_to_tab WiFi\n",
        "except:\n",
        "  pass\n",
        "victim='RAM'\n",
        "aggressor='WiFi'\n",
        "spec=1000\n",
        "zmin=0\n",
        "zmax=3000\n",
        "title=f'Wired Charging {victim} ({aggressor})'\n",
        "height=400\n",
        "width=1600\n",
        "multiaxes=True\n",
        "\n",
        "wc_plotly = WiredChargingPlotly(spec=spec, zmin=zmin, zmax=zmax, \n",
        "                                      title=title, multiaxes=multiaxes,\n",
        "                                      height=height, width=width, axis_settings=DEFAULT_AXIS_SETTINGS)\n",
        "wc_plotly.Show(wc_ram_wifi_df)\n",
        "\n",
        "\n",
        "\n",
        "try:\n",
        "  %switch_to_tab UMTS\n",
        "except:\n",
        "  pass\n",
        "victim='RAM'\n",
        "aggressor='UMTS'\n",
        "spec=1000\n",
        "zmin=0\n",
        "zmax=3000\n",
        "title=f'Wired Charging {victim} ({aggressor})'\n",
        "height=600\n",
        "width=1600\n",
        "multiaxes=True\n",
        "\n",
        "wc_plotly = WiredChargingPlotly(spec=spec, zmin=zmin, zmax=zmax, \n",
        "                                      title=title, multiaxes=multiaxes,\n",
        "                                      height=height, width=width, axis_settings=DEFAULT_AXIS_SETTINGS)\n",
        "wc_plotly.Show(wc_ram_umts_df)\n",
        "\n",
        "try:\n",
        "  %switch_to_tab LTE\n",
        "except:\n",
        "  pass\n",
        "victim='RAM'\n",
        "aggressor='LTE'\n",
        "spec=1000\n",
        "zmin=0\n",
        "zmax=3000\n",
        "title=f'Wired Charging {victim} ({aggressor})'\n",
        "height=1200\n",
        "width=1600\n",
        "multiaxes=True\n",
        "\n",
        "wc_plotly = WiredChargingPlotly(spec=spec, zmin=zmin, zmax=zmax, \n",
        "                                      title=title, multiaxes=multiaxes,\n",
        "                                      height=height, width=width, axis_settings=DEFAULT_AXIS_SETTINGS)\n",
        "wc_plotly.Show(wc_ram_lte_df)\n",
        "\n",
        "try:\n",
        "  %switch_to_tab CPU GPU Media Idle\n",
        "except:\n",
        "  pass\n",
        "victim='RAM'\n",
        "aggressor='CPU|GPU|media|idle'\n",
        "spec=1000\n",
        "zmin=0\n",
        "zmax=3000\n",
        "title=f'Wired Charging {victim} ({aggressor})'\n",
        "height=800\n",
        "width=1600\n",
        "multiaxes=True\n",
        "\n",
        "wc_plotly = WiredChargingPlotly(spec=spec, zmin=zmin, zmax=zmax, \n",
        "                                      title=title, multiaxes=multiaxes,\n",
        "                                      height=height, width=width, axis_settings=DEFAULT_AXIS_SETTINGS)\n",
        "\n",
        "wc_plotly.Show(wc_ram_misc_df)"
      ],
      "metadata": {
        "id": "l4kUN4XSeZYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title UFS Plots\n",
        "try:\n",
        "  %create_tabs  GSM, FR1, FR2, WiFi, UMTS, LTE, CPU GPU Media Idle\n",
        "  %switch_to_tab GSM\n",
        "except:\n",
        "  pass\n",
        "victim='UFS'\n",
        "aggressor='GSM'\n",
        "spec=1000\n",
        "zmin=0\n",
        "zmax=3000\n",
        "title=f'Wired Charging {victim} ({aggressor})'\n",
        "height=600\n",
        "width=1600\n",
        "multiaxes=True\n",
        "\n",
        "wc_plotly = WiredChargingPlotly(spec=spec, zmin=zmin, zmax=zmax, \n",
        "                                      title=title, multiaxes=multiaxes,\n",
        "                                      height=height, width=width, axis_settings=DEFAULT_AXIS_SETTINGS)\n",
        "wc_plotly.Show(wc_ufs_gsm_df)\n",
        "\n",
        "try:\n",
        "  %switch_to_tab FR1\n",
        "except:\n",
        "  pass\n",
        "victim='UFS'\n",
        "aggressor='FR1'\n",
        "spec=1000\n",
        "zmin=0\n",
        "zmax=3000\n",
        "title=f'Wired Charging {victim} ({aggressor})'\n",
        "height=400\n",
        "width=1600\n",
        "multiaxes=True\n",
        "\n",
        "wc_plotly = WiredChargingPlotly(spec=spec, zmin=zmin, zmax=zmax, \n",
        "                                      title=title, multiaxes=multiaxes,\n",
        "                                      height=height, width=width, axis_settings=DEFAULT_AXIS_SETTINGS)\n",
        "wc_plotly.Show(wc_ufs_fr1_df)\n",
        "\n",
        "try:\n",
        "  %switch_to_tab FR2\n",
        "except:\n",
        "  pass\n",
        "victim='UFS'\n",
        "aggressor='FR2'\n",
        "spec=1000\n",
        "zmin=0\n",
        "zmax=3000\n",
        "title=f'Wired Charging {victim} ({aggressor})'\n",
        "height=400\n",
        "width=1600\n",
        "multiaxes=True\n",
        "\n",
        "wc_plotly = WiredChargingPlotly(spec=spec, zmin=zmin, zmax=zmax, \n",
        "                                      title=title, multiaxes=multiaxes,\n",
        "                                      height=height, width=width, axis_settings=DEFAULT_AXIS_SETTINGS)\n",
        "wc_plotly.Show(wc_ufs_fr2_df)\n",
        "\n",
        "try:\n",
        "  %switch_to_tab WiFi\n",
        "except:\n",
        "  pass\n",
        "victim='UFS'\n",
        "aggressor='WiFi'\n",
        "spec=1000\n",
        "zmin=0\n",
        "zmax=3000\n",
        "title=f'Wired Charging {victim} ({aggressor})'\n",
        "height=400\n",
        "width=1600\n",
        "multiaxes=True\n",
        "\n",
        "wc_plotly = WiredChargingPlotly(spec=spec, zmin=zmin, zmax=zmax, \n",
        "                                      title=title, multiaxes=multiaxes,\n",
        "                                      height=height, width=width, axis_settings=DEFAULT_AXIS_SETTINGS)\n",
        "wc_plotly.Show(wc_ufs_wifi_df)\n",
        "\n",
        "try:\n",
        "  %switch_to_tab UMTS\n",
        "except:\n",
        "  pass\n",
        "victim='UFS'\n",
        "aggressor='UMTS'\n",
        "spec=1000\n",
        "zmin=0\n",
        "zmax=2000\n",
        "title=f'Wired Charging {victim} ({aggressor})'\n",
        "height=600\n",
        "width=1600\n",
        "multiaxes=True\n",
        "\n",
        "wc_plotly = WiredChargingPlotly(spec=spec, zmin=zmin, zmax=zmax, \n",
        "                                      title=title, multiaxes=multiaxes,\n",
        "                                      height=height, width=width, axis_settings=DEFAULT_AXIS_SETTINGS)\n",
        "wc_plotly.Show(wc_ufs_umts_df)\n",
        "\n",
        "try:\n",
        "  %switch_to_tab LTE\n",
        "except:\n",
        "  pass\n",
        "victim='UFS'\n",
        "aggressor='LTE'\n",
        "spec=1000\n",
        "zmin=0\n",
        "zmax=2000\n",
        "title=f'Wired Charging {victim} ({aggressor})'\n",
        "height=1200\n",
        "width=1600\n",
        "multiaxes=True\n",
        "\n",
        "wc_plotly = WiredChargingPlotly(spec=spec, zmin=zmin, zmax=zmax, \n",
        "                                      title=title, multiaxes=multiaxes,\n",
        "                                      height=height, width=width, axis_settings=DEFAULT_AXIS_SETTINGS)\n",
        "wc_plotly.Show(wc_ufs_lte_df)\n",
        "\n",
        "try:\n",
        "  %switch_to_tab CPU GPU Media Idle\n",
        "except:\n",
        "  pass\n",
        "victim='UFS'\n",
        "aggressor='CPU|GPU|media|idle'\n",
        "spec=1000\n",
        "zmin=0\n",
        "zmax=2000\n",
        "title=f'Wired Charging {victim} ({aggressor})'\n",
        "height=800\n",
        "width=1600\n",
        "multiaxes=True\n",
        "\n",
        "wc_plotly = WiredChargingPlotly(spec=spec, zmin=zmin, zmax=zmax, \n",
        "                                      title=title, multiaxes=multiaxes,\n",
        "                                      height=height, width=width, axis_settings=DEFAULT_AXIS_SETTINGS)\n",
        "\n",
        "wc_plotly.Show(wc_ufs_misc_df)"
      ],
      "metadata": {
        "id": "Ddjxep8ieeyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Query data table\n",
        "\n",
        "try:\n",
        "  from colabtools.interactive_table import Create as DataTable\n",
        "except:\n",
        "  from google.colab.data_table import DataTable\n",
        "\n",
        "PrintSummary(wc_df)\n",
        "DataTable(wc_df)\n",
        "\n",
        "#wc_bench_test_df.drop(columns='test_date_time', inplace=True)\n",
        "merged_df=wc_logs_df.merge(wc_bench_test_df, how='left')\n",
        "DataTable(merged_df, max_columns=30, max_rows=60000)"
      ],
      "metadata": {
        "id": "Pwo5cSACe9Iz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5ckpsdTW0fu"
      },
      "source": [
        "## Wireless Charging Post Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3blXTLPWyUE"
      },
      "source": [
        "#@title Plots\n",
        "\n",
        "wlc_df = QueryStation.wireless_charging_station()\n",
        "SensorPlotly.process(wlc_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZHfLjIPW39K"
      },
      "source": [
        "#@title Data table\n",
        "\n",
        "fail_summay = False #@param {type: 'boolean'}\n",
        "Summary.check_fail_summary(wlc_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Offsite plot\n"
      ],
      "metadata": {
        "id": "XQgD9gh2fzC9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Query Database\n",
        "test_case_pattern='^([A-Za-z0-9]+)_'\n",
        "test_item_pattern='^[A-Za-z0-9]+_(.+)$'\n",
        "station_pattern='C_3_WLC'\n",
        "\n",
        "@dataclasses.dataclass\n",
        "class WirelessChargingPlotly:\n",
        "  spec: float\n",
        "  zmax: float\n",
        "  title: str\n",
        "  multiaxes: bool\n",
        "  zmin: float\n",
        "  height: int\n",
        "  width: int\n",
        "  axis_settings: dict\n",
        "\n",
        "  def _BuildHeapmap(self, df_x, df_y, df_z, df_hover):\n",
        "    return Heatmap(\n",
        "        z=df_z,\n",
        "        x=df_x,\n",
        "        y=df_y,\n",
        "        xgap=2,\n",
        "        ygap=2,\n",
        "        zmin = self.zmin,\n",
        "        zmax = self.zmax,\n",
        "        hoverinfo='x+y+z+text',\n",
        "        text=df_hover,\n",
        "    )\n",
        "\n",
        "  def _BuildTraceFigure(self, df):\n",
        "    df_hover = df[['result', 'message']].apply(lambda x: 'Result: {}<br>Message: {}'.format(x[0], x[1]), axis=1)\n",
        "    data = [self._BuildHeapmap(df.serial, df.test_item, df.value, df_hover)]\n",
        "    \n",
        "    layout = Layout(\n",
        "        title=self.title,\n",
        "        xaxis = self.axis_settings,\n",
        "        yaxis = self.axis_settings,\n",
        "        height=self.height,\n",
        "        width=self.width,\n",
        "    )\n",
        "    return Figure(data=data, layout=layout)\n",
        "\n",
        "  def Show(self, df):\n",
        "    fig = self._BuildTraceFigure(df)\n",
        "    fig.show()\n",
        "\n",
        "wlc_test_df = QueryData(Table.FACTORY, Project, BUILD_PHASE[Build], station_pattern, test_case_pattern=test_case_pattern, \n",
        "                                         test_item_pattern=test_item_pattern)\n",
        "\n",
        "wlc_logs_df = QueryData(Table.LOGS, Project, BUILD_PHASE[Build], station_pattern)\n",
        "\n",
        "# get latest one\n",
        "wlc_bench_test_df = wlc_test_df[wlc_test_df.test_item.notna() & wlc_test_df.test_item.str.contains('bench')].copy()\n",
        "wlc_bench_test_df = wlc_bench_test_df.sort_values(by=['test_date_time'], ascending=False)\n",
        "wlc_bench_test_df = wlc_bench_test_df.drop_duplicates(['serial', 'test_case', 'test_item'])\n",
        "wlc_bench_test_df.drop(columns='test_date_time', inplace=True)\n",
        "\n",
        "wc_logs_df = wc_logs_df.sort_values(by=['test_date_time'], ascending=False)\n",
        "wc_logs_df = wc_logs_df.drop_duplicates(['serial', 'test_case'])\n",
        "\n",
        "victim='RAM105'\n",
        "aggressor='n[0-9]+'\n",
        "wlc_ram_fr1_df = ProcessUfsRamDataframe(wlc_bench_test_df, wlc_logs_df, victim, aggressor)\n",
        "\n",
        "victim='RAM106'\n",
        "aggressor='n[0-9]+'\n",
        "wlc_ram_fr2_df = ProcessUfsRamDataframe(wlc_bench_test_df, wlc_logs_df, victim, aggressor)\n",
        "\n",
        "victim='RAM'\n",
        "aggressor='GSM'\n",
        "wlc_ram_gsm_df = ProcessUfsRamDataframe(wlc_bench_test_df, wlc_logs_df, victim, aggressor)\n",
        "\n",
        "aggressor='802_11'\n",
        "wlc_ram_wifi_df = ProcessUfsRamDataframe(wlc_bench_test_df, wlc_logs_df, victim, aggressor)\n",
        "\n",
        "aggressor='UMTS'\n",
        "wlc_ram_umts_df = ProcessUfsRamDataframe(wlc_bench_test_df, wlc_logs_df, victim, aggressor)\n",
        "\n",
        "aggressor='LTE'\n",
        "wlc_ram_lte_df = ProcessUfsRamDataframe(wlc_bench_test_df, wlc_logs_df, victim, aggressor)\n",
        "\n",
        "misc_aggerssors=['CPU', 'GPU', 'media', 'idle']\n",
        "wlc_ram_misc_df = pandas.DataFrame(columns=wlc_ram_gsm_df.columns)\n",
        "for aggressor in misc_aggerssors:\n",
        "  wlc_ram_misc_df = wlc_ram_misc_df.append(ProcessUfsRamDataframe(wlc_bench_test_df, wlc_logs_df, victim, aggressor))\n",
        "\n",
        "victim='UFS105'\n",
        "aggressor='n[0-9]+'\n",
        "wlc_ufs_fr1_df = ProcessUfsRamDataframe(wlc_bench_test_df, wlc_logs_df, victim, aggressor)\n",
        "\n",
        "victim='UFS106'\n",
        "aggressor='n[0-9]+'\n",
        "wlc_ufs_fr2_df = ProcessUfsRamDataframe(wlc_bench_test_df, wlc_logs_df, victim, aggressor)\n",
        "\n",
        "victim='UFS'\n",
        "aggressor='GSM'\n",
        "wlc_ufs_gsm_df = ProcessUfsRamDataframe(wlc_bench_test_df, wlc_logs_df, victim, aggressor)\n",
        "\n",
        "aggressor='802_11'\n",
        "wlc_ufs_wifi_df = ProcessUfsRamDataframe(wlc_bench_test_df, wlc_logs_df, victim, aggressor)\n",
        "\n",
        "aggressor='UMTS'\n",
        "wlc_ufs_umts_df = ProcessUfsRamDataframe(wlc_bench_test_df, wlc_logs_df, victim, aggressor)\n",
        "\n",
        "aggressor='LTE'\n",
        "wlc_ufs_lte_df = ProcessUfsRamDataframe(wlc_bench_test_df, wlc_logs_df, victim, aggressor)\n",
        "\n",
        "misc_aggerssors=['CPU', 'GPU', 'media', 'idle']\n",
        "wlc_ufs_misc_df = pandas.DataFrame(columns=wlc_ram_gsm_df.columns)\n",
        "for aggressor in misc_aggerssors:\n",
        "  wlc_ufs_misc_df = wlc_ufs_misc_df.append(ProcessUfsRamDataframe(wlc_bench_test_df, wlc_logs_df, victim, aggressor))\n",
        "\n",
        "wlc_df = wlc_ram_gsm_df.append(wlc_ram_fr1_df).append(wlc_ram_fr2_df).append(wlc_ram_wifi_df).append(wlc_ram_umts_df).append(wlc_ram_lte_df).append(wlc_ram_misc_df)\n",
        "wlc_df = wlc_df.append(wlc_ufs_gsm_df).append(wlc_ufs_fr1_df).append(wlc_ufs_fr2_df).append(wlc_ufs_wifi_df).append(wlc_ufs_umts_df).append(wlc_ufs_lte_df).append(wlc_ufs_misc_df)"
      ],
      "metadata": {
        "id": "JgkyE-pDf4ga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title RAM Plots\n",
        "try:\n",
        "  %create_tabs  GSM, FR1, FR2, WiFi, UMTS, LTE, CPU GPU Media Idle\n",
        "  %switch_to_tab GSM\n",
        "except:\n",
        "  pass\n",
        "victim='RAM'\n",
        "aggressor='GSM'\n",
        "spec=1000\n",
        "zmin=0\n",
        "zmax=3000\n",
        "title=f'Wireless Charging {victim} ({aggressor})'\n",
        "height=600\n",
        "width=1600\n",
        "multiaxes=True\n",
        "\n",
        "wlc_plotly = WirelessChargingPlotly(spec=spec, zmin=zmin, zmax=zmax, \n",
        "                                      title=title, multiaxes=multiaxes,\n",
        "                                      height=height, width=width, axis_settings=DEFAULT_AXIS_SETTINGS)\n",
        "wlc_plotly.Show(wlc_ram_gsm_df)\n",
        "\n",
        "try:\n",
        "  %switch_to_tab FR1\n",
        "except:\n",
        "  pass\n",
        "victim='RAM'\n",
        "aggressor='FR1'\n",
        "spec=1000\n",
        "zmin=0\n",
        "zmax=3000\n",
        "title=f'Wireless Charging {victim} ({aggressor})'\n",
        "height=400\n",
        "width=1600\n",
        "multiaxes=True\n",
        "\n",
        "wlc_plotly = WirelessChargingPlotly(spec=spec, zmin=zmin, zmax=zmax, \n",
        "                                      title=title, multiaxes=multiaxes,\n",
        "                                      height=height, width=width, axis_settings=DEFAULT_AXIS_SETTINGS)\n",
        "wlc_plotly.Show(wlc_ram_fr1_df)\n",
        "\n",
        "try:\n",
        "  %switch_to_tab FR2\n",
        "except:\n",
        "  pass\n",
        "victim='RAM'\n",
        "aggressor='FR2'\n",
        "spec=1000\n",
        "zmin=0\n",
        "zmax=3000\n",
        "title=f'Wireless Charging {victim} ({aggressor})'\n",
        "height=400\n",
        "width=1600\n",
        "multiaxes=True\n",
        "\n",
        "wlc_plotly = WirelessChargingPlotly(spec=spec, zmin=zmin, zmax=zmax, \n",
        "                                      title=title, multiaxes=multiaxes,\n",
        "                                      height=height, width=width, axis_settings=DEFAULT_AXIS_SETTINGS)\n",
        "wlc_plotly.Show(wlc_ram_fr2_df)\n",
        "\n",
        "try:\n",
        "  %switch_to_tab WiFi\n",
        "except:\n",
        "  pass\n",
        "victim='RAM'\n",
        "aggressor='WiFi'\n",
        "spec=1000\n",
        "zmin=0\n",
        "zmax=3000\n",
        "title=f'Wireless Charging {victim} ({aggressor})'\n",
        "height=400\n",
        "width=1600\n",
        "multiaxes=True\n",
        "\n",
        "wlc_plotly = WirelessChargingPlotly(spec=spec, zmin=zmin, zmax=zmax, \n",
        "                                      title=title, multiaxes=multiaxes,\n",
        "                                      height=height, width=width, axis_settings=DEFAULT_AXIS_SETTINGS)\n",
        "wlc_plotly.Show(wlc_ram_wifi_df)\n",
        "\n",
        "try:\n",
        "  %switch_to_tab UMTS\n",
        "except:\n",
        "  pass\n",
        "victim='RAM'\n",
        "aggressor='UMTS'\n",
        "spec=1000\n",
        "zmin=0\n",
        "zmax=3000\n",
        "title=f'Wireless Charging {victim} ({aggressor})'\n",
        "height=600\n",
        "width=1600\n",
        "multiaxes=True\n",
        "\n",
        "wlc_plotly = WirelessChargingPlotly(spec=spec, zmin=zmin, zmax=zmax, \n",
        "                                      title=title, multiaxes=multiaxes,\n",
        "                                      height=height, width=width, axis_settings=DEFAULT_AXIS_SETTINGS)\n",
        "wlc_plotly.Show(wlc_ram_umts_df)\n",
        "\n",
        "try:\n",
        "  %switch_to_tab LTE\n",
        "except:\n",
        "  pass\n",
        "victim='RAM'\n",
        "aggressor='LTE'\n",
        "spec=1000\n",
        "zmin=0\n",
        "zmax=3000\n",
        "title=f'Wireless Charging {victim} ({aggressor})'\n",
        "height=1200\n",
        "width=1600\n",
        "multiaxes=True\n",
        "\n",
        "wlc_plotly = WirelessChargingPlotly(spec=spec, zmin=zmin, zmax=zmax, \n",
        "                                      title=title, multiaxes=multiaxes,\n",
        "                                      height=height, width=width, axis_settings=DEFAULT_AXIS_SETTINGS)\n",
        "wlc_plotly.Show(wlc_ram_lte_df)\n",
        "\n",
        "try:\n",
        "  %switch_to_tab CPU GPU Media Idle\n",
        "except:\n",
        "  pass\n",
        "victim='RAM'\n",
        "aggressor='CPU|GPU|media|idle'\n",
        "spec=1000\n",
        "zmin=0\n",
        "zmax=3000\n",
        "title=f'Wireless Charging {victim} ({aggressor})'\n",
        "height=800\n",
        "width=1600\n",
        "multiaxes=True\n",
        "\n",
        "wlc_plotly = WirelessChargingPlotly(spec=spec, zmin=zmin, zmax=zmax, \n",
        "                                      title=title, multiaxes=multiaxes,\n",
        "                                      height=height, width=width, axis_settings=DEFAULT_AXIS_SETTINGS)\n",
        "wlc_plotly.Show(wlc_ram_misc_df)"
      ],
      "metadata": {
        "id": "_4MfZCvnf-tm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title UFS Plots\n",
        "try:\n",
        "  %create_tabs  GSM, FR1, FR2, WiFi, UMTS, LTE, CPU GPU Media Idle\n",
        "  %switch_to_tab GSM\n",
        "except:\n",
        "  pass\n",
        "victim='UFS'\n",
        "aggressor='GSM'\n",
        "spec=1000\n",
        "zmin=0\n",
        "zmax=3000\n",
        "title=f'Wireless Charging {victim} ({aggressor})'\n",
        "height=600\n",
        "width=1600\n",
        "multiaxes=True\n",
        "\n",
        "wlc_plotly = WirelessChargingPlotly(spec=spec, zmin=zmin, zmax=zmax, \n",
        "                                      title=title, multiaxes=multiaxes,\n",
        "                                      height=height, width=width, axis_settings=DEFAULT_AXIS_SETTINGS)\n",
        "wlc_plotly.Show(wlc_ufs_gsm_df)\n",
        "\n",
        "try:\n",
        "  %switch_to_tab FR1\n",
        "except:\n",
        "  pass\n",
        "victim='UFS'\n",
        "aggressor='FR1'\n",
        "spec=1000\n",
        "zmin=0\n",
        "zmax=3000\n",
        "title=f'Wireless Charging {victim} ({aggressor})'\n",
        "height=400\n",
        "width=1600\n",
        "multiaxes=True\n",
        "\n",
        "wlc_plotly = WirelessChargingPlotly(spec=spec, zmin=zmin, zmax=zmax, \n",
        "                                      title=title, multiaxes=multiaxes,\n",
        "                                      height=height, width=width, axis_settings=DEFAULT_AXIS_SETTINGS)\n",
        "wlc_plotly.Show(wlc_ufs_fr1_df)\n",
        "\n",
        "try:\n",
        "  %switch_to_tab FR2\n",
        "except:\n",
        "  pass\n",
        "victim='UFS'\n",
        "aggressor='FR2'\n",
        "spec=1000\n",
        "zmin=0\n",
        "zmax=3000\n",
        "title=f'Wireless Charging {victim} ({aggressor})'\n",
        "height=400\n",
        "width=1600\n",
        "multiaxes=True\n",
        "\n",
        "wlc_plotly = WirelessChargingPlotly(spec=spec, zmin=zmin, zmax=zmax, \n",
        "                                      title=title, multiaxes=multiaxes,\n",
        "                                      height=height, width=width, axis_settings=DEFAULT_AXIS_SETTINGS)\n",
        "wlc_plotly.Show(wlc_ufs_fr2_df)\n",
        "\n",
        "try:\n",
        "  %switch_to_tab WiFi\n",
        "except:\n",
        "  pass\n",
        "victim='UFS'\n",
        "aggressor='WiFi'\n",
        "spec=1000\n",
        "zmin=0\n",
        "zmax=3000\n",
        "title=f'Wireless Charging {victim} ({aggressor})'\n",
        "height=400\n",
        "width=1600\n",
        "multiaxes=True\n",
        "\n",
        "wlc_plotly = WirelessChargingPlotly(spec=spec, zmin=zmin, zmax=zmax, \n",
        "                                      title=title, multiaxes=multiaxes,\n",
        "                                      height=height, width=width, axis_settings=DEFAULT_AXIS_SETTINGS)\n",
        "wlc_plotly.Show(wlc_ufs_wifi_df)\n",
        "try:\n",
        "  %switch_to_tab UMTS\n",
        "except:\n",
        "  pass\n",
        "victim='UFS'\n",
        "aggressor='UMTS'\n",
        "spec=1000\n",
        "zmin=0\n",
        "zmax=2000\n",
        "title=f'Wireless Charging {victim} ({aggressor})'\n",
        "height=600\n",
        "width=1600\n",
        "multiaxes=True\n",
        "\n",
        "wlc_plotly = WirelessChargingPlotly(spec=spec, zmin=zmin, zmax=zmax, \n",
        "                                      title=title, multiaxes=multiaxes,\n",
        "                                      height=height, width=width, axis_settings=DEFAULT_AXIS_SETTINGS)\n",
        "wlc_plotly.Show(wlc_ufs_umts_df)\n",
        "\n",
        "try:\n",
        "  %switch_to_tab LTE\n",
        "except:\n",
        "  pass\n",
        "victim='UFS'\n",
        "aggressor='LTE'\n",
        "spec=1000\n",
        "zmin=0\n",
        "zmax=2000\n",
        "title=f'Wireless Charging {victim} ({aggressor})'\n",
        "height=1200\n",
        "width=1600\n",
        "multiaxes=True\n",
        "\n",
        "wlc_plotly = WirelessChargingPlotly(spec=spec, zmin=zmin, zmax=zmax, \n",
        "                                      title=title, multiaxes=multiaxes,\n",
        "                                      height=height, width=width, axis_settings=DEFAULT_AXIS_SETTINGS)\n",
        "wlc_plotly.Show(wlc_ufs_lte_df)\n",
        "\n",
        "try:\n",
        "  %switch_to_tab CPU GPU Media Idle\n",
        "except:\n",
        "  pass\n",
        "victim='UFS'\n",
        "aggressor='CPU|GPU|media|idle'\n",
        "spec=1000\n",
        "zmin=0\n",
        "zmax=2000\n",
        "title=f'Wireless Charging {victim} ({aggressor})'\n",
        "height=800\n",
        "width=1600\n",
        "multiaxes=True\n",
        "\n",
        "wlc_plotly = WirelessChargingPlotly(spec=spec, zmin=zmin, zmax=zmax, \n",
        "                                      title=title, multiaxes=multiaxes,\n",
        "                                      height=height, width=width, axis_settings=DEFAULT_AXIS_SETTINGS)\n",
        "wlc_plotly.Show(wlc_ufs_misc_df)"
      ],
      "metadata": {
        "id": "A8CSmblLgDLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Query Database\n",
        "\n",
        "try:\n",
        "  from colabtools.interactive_table import Create as DataTable\n",
        "except:\n",
        "  from google.colab.data_table import DataTable\n",
        "\n",
        "PrintSummary(wlc_df)\n",
        "DataTable(wlc_df)"
      ],
      "metadata": {
        "id": "f6D4f2aMgHaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rtt1LtvqXGQO"
      },
      "source": [
        "# Revision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQOPBAiKXJlt"
      },
      "source": [
        "Revision Note:\n",
        "- v0.5.11\n",
        "  - Plot with station and camera id controll.\n",
        "  "
      ]
    }
  ]
}